{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title_cell"
   },
   "source": [
    "# KultuRAG: Cultural AI Language Learning Assistant with RAG\n",
    "# Combined Frontend & Backend\n",
    "\n",
    "This notebook runs the entire KultuRAG application. It starts a FastAPI backend and a Streamlit frontend, exposing them through a single public URL using ngrok.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Run all the cells in order\n",
    "2.  The final cell will provide a public ngrok URL\n",
    "3.  Click the URL to open your fully functional application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rcs_hT4ivsiz"
   },
   "source": [
    "## 1. Install and import packages / Project configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "install_deps",
    "outputId": "3f226516-9912-41f6-cc53-d5ef21f1fef9"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.3/337.3 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.9/216.9 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.4/189.4 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.5/35.5 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 45.0.6 which is incompatible.\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  libportaudio2\n",
      "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
      "Need to get 65.3 kB of archives.\n",
      "After this operation, 223 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudio2 amd64 19.6.0-1.1 [65.3 kB]\n",
      "Fetched 65.3 kB in 0s (176 kB/s)\n",
      "Selecting previously unselected package libportaudio2:amd64.\n",
      "(Reading database ... 126371 files and directories currently installed.)\n",
      "Preparing to unpack .../libportaudio2_19.6.0-1.1_amd64.deb ...\n",
      "Unpacking libportaudio2:amd64 (19.6.0-1.1) ...\n",
      "Setting up libportaudio2:amd64 (19.6.0-1.1) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Install packages\n",
    "!pip -q install fastapi uvicorn pydantic pyngrok streamlit requests langchain-google-vertexai langchain-qdrant langchain-huggingface\n",
    "!pip -q install langchain wikipedia google-cloud-aiplatform google-auth streamlit-webrtc pydub google-cloud-texttospeech google-cloud-speech\n",
    "!apt-get install -y libportaudio2"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Authentication\n",
    "import os\n",
    "from google.colab import auth, userdata\n",
    "\n",
    "# Set the application default credentials for all Python libraries\n",
    "!gcloud auth application-default login\n",
    "\n",
    "# Set the project ID\n",
    "project_ID = userdata.get('gcloud_project')\n",
    "!gcloud config set project {project_ID}\n",
    "os.environ[\"GCLOUD_PROJECT\"] = project_ID\n",
    "\n",
    "# Standard Colab auth for full integration\n",
    "auth.authenticate_user(project_id=project_ID)\n",
    "\n",
    "# Link the credentials to project for billing quota\n",
    "!gcloud auth application-default set-quota-project {project_ID}"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Iu9UWSWCXTZ",
    "outputId": "6c5504db-81bb-4a2b-941b-52a93f5bad6f"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Go to the following link in your browser, and complete the sign-in prompts:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fapplicationdefaultauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=ovZq3TxjHlAhvLniAqDB6GqBtRaQQl&prompt=consent&token_usage=remote&access_type=offline&code_challenge=cltoEc1jl0DJIEBxW1FUPiY2CKSKRYBPmAj_ijyfIcg&code_challenge_method=S256\n",
      "\n",
      "Once finished, enter the verification code provided in your browser: 4/0AVMBsJhfl7G7iv0aeDM7RfZmtcBII18g212eMQlYH-YkQmUZnhwhWVOhOvfpBpc1Kg_YKQ\n",
      "\n",
      "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
      "\n",
      "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
      "\u001b[1;33mWARNING:\u001b[0m \n",
      "Cannot find a quota project to add to ADC. You might receive a \"quota exceeded\" or \"API not enabled\" error. Run $ gcloud auth application-default set-quota-project to add a quota project.\n",
      "\u001b[1;33mWARNING:\u001b[0m Your active project does not match the quota project in your local Application Default Credentials file. This might result in unexpected quota issues.\n",
      "\n",
      "To update your Application Default Credentials quota project, use the `gcloud auth application-default set-quota-project` command.\n",
      "Updated property [core/project].\n",
      "\n",
      "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
      "\n",
      "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
      "\n",
      "Quota project \"spherical-treat-466107-r3\" was added to ADC which can be used by Google client libraries for billing and quota. Note that some services may still bill the project owning the resource.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "import_and_auth",
    "outputId": "f5bb4094-5680-4b80-c17b-59e612202ea7"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:300: SyntaxWarning: invalid escape sequence '\\('\n",
      "  m = re.match('([su]([0-9]{1,2})p?) \\(([0-9]{1,2}) bit\\)$', token)\n",
      "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:301: SyntaxWarning: invalid escape sequence '\\('\n",
      "  m2 = re.match('([su]([0-9]{1,2})p?)( \\(default\\))?$', token)\n",
      "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:310: SyntaxWarning: invalid escape sequence '\\('\n",
      "  elif re.match('(flt)p?( \\(default\\))?$', token):\n",
      "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:314: SyntaxWarning: invalid escape sequence '\\('\n",
      "  elif re.match('(dbl)p?( \\(default\\))?$', token):\n",
      "2025-08-24 18:33:57.898 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-08-24 18:33:57.901 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-08-24 18:33:57.903 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-08-24 18:33:58.141 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-24 18:33:58.143 No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import sys, wikipedia, threading, time, os, vertexai, uvicorn, requests, json, base64, io, av\n",
    "from langchain_google_vertexai import VertexAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from google.colab import auth, userdata\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from pyngrok import ngrok\n",
    "import streamlit as st\n",
    "from google.cloud import texttospeech\n",
    "from google.cloud import speech_v1\n",
    "from pydub import AudioSegment\n",
    "from streamlit_webrtc import webrtc_streamer, WebRtcMode\n",
    "import streamlit.components.v1 as components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E99sKkd2xAJq"
   },
   "source": [
    "## 2. Project configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "config_settings",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8d12583b-38b7-4e5b-a6e5-35d569be6be2"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
     ]
    }
   ],
   "source": [
    "# Project settings\n",
    "# Project parameters\n",
    "location = \"europe-west4\"\n",
    "\n",
    "# Qdrant Configuration\n",
    "collection_name = \"KultuRAG\"\n",
    "qdrant_URL = userdata.get('QDRANT_URL')\n",
    "qdrant_API_key = userdata.get('QDRANT_API_KEY')\n",
    "\n",
    "# ngrok Configuration\n",
    "ngrok_auth_token = userdata.get('NGROK_AUTH_TOKEN')\n",
    "!ngrok config add-authtoken ngrok_auth_token  # Add ngrok token to project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6aGWk7SSxQgS"
   },
   "source": [
    "## 3. Backend\n",
    "\n",
    "This is the core logic of the application, containing all the functions that power the app AI features.\n",
    "\n",
    "**Helper Functions:** This part defines functions to initialize and manage different components.\n",
    "\n",
    "* search_wikipedia_topic: Searches Wikipedia in German for a given topic to provide cultural context for the AI.\n",
    "\n",
    "* initialize_embeddings and initialize_vector_store: Set up the connection to the Qdrant vector database, which stores German sentence examples for the RAG system.\n",
    "\n",
    "* initialize_llm1 and initialize_llm2: Configure two separate instances of the Gemini language model. One is tuned for creative content generation (exercises) and the other is set for more precise responses (feedback).\n",
    "\n",
    "* create_prompt_template: Contains prompt templates that instruct the AI on how to generate reading, writing, listening and speaking exercises, as well as how to provide feedback.\n",
    "\n",
    "* initialize_tts and initialize_stt: Set up Google's Text-to-Speech and Speech-to-Text clients for audio features.\n",
    "\n",
    "**Backend Initialization:** This cell brings all the helper functions together. It initializes the embedding model, connects to the vector store, and prepares the LLMs and prompt templates for use.\n",
    "\n",
    "**FastAPI Application:** This defines the backend server using FastAPI. It sets up several API endpoints that the frontend can call.\n",
    "\n",
    "* /generate_exercises: The main endpoint that takes a topic, language level, and content type from the user. It retrieves relevant data from Wikipedia and the Qdrant vector store. Then, it uses the LLM to generate a complete set of learning materials and exercises.\n",
    "\n",
    "* /feedback: Takes a user's answer to an exercise and generates pedagogical feedback.\n",
    "\n",
    "* /tts and /stt: Handle text-to-speech and speech-to-text conversions for the audio exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "backend_helpers"
   },
   "outputs": [],
   "source": [
    "# Backend helper functions\n",
    "def search_wikipedia_topic(topic, sentences=10):\n",
    "    \"\"\"\n",
    "    Search topic on Wikipedia for cultural and contextual information about it\n",
    "\n",
    "    Args:\n",
    "        topic (str): Topic to search for  // * topic is the topic introduced by the user to formulate the output of the model\n",
    "        sentences (int): Number of sentences in the summary to return\n",
    "\n",
    "    Returns:\n",
    "        str: Wikipedia summary or error message\n",
    "    \"\"\"\n",
    "    try:\n",
    "        wikipedia.set_lang('de')  # Set language to German\n",
    "        search_results = wikipedia.search(topic, results=1)  # Search for the first result of the topic elected by the user\n",
    "        if not search_results:  # If no results are found\n",
    "            return f\"No cultural information found about {topic} on Wikipedia.\"\n",
    "        summary = wikipedia.summary(search_results[0], sentences=sentences)\n",
    "        return summary\n",
    "    except wikipedia.exceptions.DisambiguationError as e:  # If many results are found\n",
    "        try:\n",
    "            return wikipedia.summary(e.options[0], sentences=sentences)  # Choose first result and create summary\n",
    "        except:  # If it fails\n",
    "            return f\"Multiple meanings found for {topic}. Please be more specific\"\n",
    "    except Exception:  # If search fails\n",
    "        return f\"No Wikipedia information found for {topic}\"\n",
    "\n",
    "def initialize_embeddings():\n",
    "    \"\"\"\n",
    "    Initialize embeddings model for vector store\n",
    "\n",
    "    Returns embeddings instance\n",
    "    \"\"\"\n",
    "    # Same model as the model used for indexing\n",
    "    model_name = 'sentence-transformers/all-MiniLM-L6-v2'  # 22.7M parameters, 80MB, open-source\n",
    "    return HuggingFaceEmbeddings(model_name=model_name)\n",
    "\n",
    "def initialize_vector_store(embeddings):\n",
    "    \"\"\"\n",
    "    Initialize Qdrant vector store connection\n",
    "\n",
    "    Args:\n",
    "        embeddings: Embeddings model\n",
    "        collection_name (str): Name of the Qdrant collection\n",
    "        url (str): Qdrant instance URL\n",
    "        api_key (str): Qdrant API key\n",
    "\n",
    "    Returns configured vector store instance or None if connection fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return QdrantVectorStore.from_existing_collection(\n",
    "            embedding=embeddings,  # Embedding model instance\n",
    "            collection_name=collection_name,\n",
    "            url=qdrant_URL,  # Qdrant server URL\n",
    "            api_key=qdrant_API_key,  # Qdrant API key\n",
    "            timeout=300.0  # Give the vector store 5 minutes to find results and not fail\n",
    "        )\n",
    "    except Exception as e:  # If connection fails\n",
    "        print(f\"Could not connect to Qdrant. Proceeding without vector examples. Error: {e}\")\n",
    "        return None  # Return nothing and continue without vector store\n",
    "\n",
    "def initialize_llm1():\n",
    "    \"\"\"\n",
    "    Initialize the language model with the project configuration for exercises\n",
    "\n",
    "    The model will return focused but creative responses\n",
    "\n",
    "    Returns configured language model instance 1\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create the LLM instance\n",
    "        vertexai.init(project=project_ID, location=location)\n",
    "        return VertexAI(\n",
    "            model_name=\"gemini-2.5-flash-lite\",\n",
    "            max_output_tokens=9000,\n",
    "            temperature=0.6,  # Middle temperature for focused but creative responses\n",
    "            top_p=0.8,\n",
    "            verbose=False,  # Disable verbose logging\n",
    "            project=project_ID,\n",
    "            location=location\n",
    "        )\n",
    "    except Exception as e:  # If Vertex AI initialisation fails\n",
    "        print(f\"Error initializing Vertex AI model: {e}\")\n",
    "        print(\"Check credentials and API access\")\n",
    "        return None\n",
    "\n",
    "def initialize_llm2():\n",
    "    \"\"\"\n",
    "    Initialize the language model with the project configuration for feedback\n",
    "\n",
    "    The model will return very focused responses without hallucinations\n",
    "\n",
    "    Returns configured language model instance 2\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create the LLM instance\n",
    "        vertexai.init(project=project_ID, location=location)\n",
    "        return VertexAI(\n",
    "            model_name=\"gemini-2.5-flash-lite\",\n",
    "            max_output_tokens=9000,\n",
    "            temperature=0.1,  # Lower temperature for more focused, less random responses\n",
    "            top_p=0.7,\n",
    "            verbose=False,  # Disable verbose logging\n",
    "            project=project_ID,\n",
    "            location=location\n",
    "        )\n",
    "    except Exception as e:  # If Vertex AI initialisation fails\n",
    "        print(f\"Error initializing Vertex AI model: {e}\")\n",
    "        print(\"Please check credentials and API access\")\n",
    "        return None\n",
    "\n",
    "def validate_inputs(topic, level, content_type):\n",
    "    \"\"\"\n",
    "    Validate user inputs for content generation\n",
    "\n",
    "    Args:\n",
    "        topic (str): Learning topic\n",
    "        level (str): Language level\n",
    "        content_type (str): Type of content to generate\n",
    "\n",
    "    Returns:\n",
    "        tuple: (is_valid, error_message)\n",
    "    \"\"\"\n",
    "    valid_levels = ['A1', 'A2', 'B1', 'B2', 'C1', 'C2']  # List with valid level options\n",
    "    valid_types = ['Kurztext', 'Langtext', 'Geschichte', 'Märchen', 'Dialog',\n",
    "                   'Interview', 'Redewendung', 'Rolenspiel', 'Gedicht', 'Drama', 'Liedtext',\n",
    "                   'Online-Gespräch', 'Jugendsprache']  # List with valid content type options\n",
    "\n",
    "    if not topic or len(topic.strip()) < 2:  # If topic is not valid or not introduced\n",
    "        return False, \"Please provide a valid topic (at least 2 characters).\"\n",
    "\n",
    "    if level not in valid_levels:  # If level introduced is not valid\n",
    "        return False, f\"Language level must be one of: {', '.join(valid_levels)}\"\n",
    "\n",
    "    if content_type not in valid_types:  # If content type introduced is not valid\n",
    "        return False, f\"Content type must be one of: {', '.join(valid_types)}\"\n",
    "\n",
    "    return True, \"\"  # If every input introduced is correct, return true\n",
    "\n",
    "# Prompts\n",
    "def create_prompt_template():  # Main prompt, for Leseverstehen\n",
    "    \"\"\"\n",
    "    Create a pedagogical prompt template with proper structure and formatting\n",
    "\n",
    "    Returns Prompt template for language learning content\n",
    "    \"\"\"\n",
    "    template = \"\"\"\n",
    "Du bist ein erfahrener Sprachlernexperte und Pädagoge. Deine Aufgabe ist es, hochwertigen, lernzielorientierten Inhalt zu erstellen, der kulturell authentisch und didaktisch wertvoll ist.\n",
    "Generiere ausschließlich den gewünschten Inhalt unter Berücksichtigung der unten aufgeführten Anweisungen. Verzichte auf Einleitungen, Erklärungen oder Kommentare wie ‚Klar‘, ‚Hier ist dein Inhalt‘ usw., die nicht Teil der Anweisungen sind.\n",
    "**Behalte ein geordnetes, klares und schönes Design bei. Wenn du Aufzählungspunkte verwendest, setze jeden Aufzählungspunkt in eine neue Zeile. Vom Ausgabeformat dieses Prompts must du die Setzung der Zeilenumbrüche ('\\n') beachten.**\n",
    "\n",
    "LERNSPEZIFIKATIONEN\n",
    "THEMA: {topic}\n",
    "SPRACHNIVEAU: {level}\n",
    "INHALTSTYP: {content_type}\n",
    "ZIELSPRACHE: Deutsch\n",
    "\n",
    "VERFÜGBARE RESSOURCEN\n",
    "NATÜRLICHE SPRACHBEISPIELE AUS DATENBANK: {natural_examples}\n",
    "KULTURELLER KONTEXT AUS WIKIPEDIA: {cultural_context}\n",
    "\n",
    "PÄDAGOGISCHE ANWEISUNGEN\n",
    "1. **INHALTSERSTELLUNG:** Erstelle einen authentischen, kulturell relevanten {content_type} über {topic}, der perfekt für das {level}-Niveau geeignet ist.\n",
    "2. **SPRACHNIVEAU-ANPASSUNG:**\n",
    "   - Wähle Wortschatz und Grammatik entsprechend dem angegebenen Niveau\n",
    "   - Verwende angemessene Satzstrukturen und Komplexität\n",
    "   - Berücksichtige typische Lernziele für dieses Niveau\n",
    "3. **KULTURELLE AUTHENTIZITÄT:** Integriere die Wikipedia-Informationen geschickt, um kulturelle Tiefe und Kontext zu schaffen.\n",
    "4. **NATÜRLICHE SPRACHE:** Nutze die Beispiele aus der Datenbank als Inspiration für natürlichen, idiomatischen Sprachgebrauch.\n",
    "5. **LERNFÖRDERUNG:** Der Inhalt soll interessant, einprägsam und lernmotivierend sein.\n",
    "6. **INTERAKTIVE LERNÜBUNG:**\n",
    "   - Die Übung muss passend und mit Bezug zum generierten Inhalt sein, aber neu, originell und herausfordernd.\n",
    "   - Zeige Keine Lösungen für die Übung\n",
    "\n",
    "AUSGABEFORMAT (GENAU BEFOLGEN!)\n",
    "**🎯 {content_type_upper} - SPRACHNIVEAU {level_upper}**\n",
    "\n",
    "[Hier steht dein generierter Lerninhalt - authentisch, kulturell relevant und sprachniveau-gerecht]\\n\\n\n",
    "\n",
    "\n",
    "**🔍 SCHWIERIGKEITSEINSCHÄTZUNG**\n",
    "\n",
    "📊 **Dieser Text entspricht dem Niveau:** {level_upper}\\n\n",
    "🎯 **Lernziele:** [2-3 spezifische Lernziele, die mit diesem Inhalt erreicht werden]\\n\n",
    "⏱️ **Geschätzte Bearbeitungszeit:** [X Minuten]\\n\\n\n",
    "\n",
    "\n",
    "**📚 SCHLÜSSELVOKABULAR**\n",
    "\n",
    "• **Wort 1** - [Erklärung/Definition + Beispielsatz]\\n\n",
    "• **Wort 2** - [Erklärung/Definition + Beispielsatz]\\n\n",
    "• **Wort 3** - [Erklärung/Definition + Beispielsatz]\\n\n",
    "[... weitere wichtige Vokabeln ...]\\n\\n\n",
    "\n",
    "\n",
    "**🎮 LERNÜBUNG**\n",
    "\n",
    "[Erstelle eine der folgenden Übungstypen:]\n",
    "- Lückentext mit Auswahlantworten\n",
    "- Multiple-Choice-Fragen zum Textverständnis\n",
    "- Richtig/Falsch-Aussagen\n",
    "- Wortschatz-Zuordnungsaufgabe\n",
    "\n",
    "\\n\\n\n",
    "\"\"\"\n",
    "\n",
    "    # Return prompt template with necessary variables\n",
    "    return PromptTemplate(\n",
    "        input_variables=[\"topic\", \"level\", \"level_upper\", \"content_type\", \"content_type_upper\", \"natural_examples\", \"cultural_context\"],\n",
    "        template=template\n",
    "    )\n",
    "\n",
    "def create_writing_exercise_prompt():\n",
    "    \"\"\"\n",
    "    Create prompt template for writing exercise instructions\n",
    "\n",
    "    Returns prompt template for writing exercise\n",
    "    \"\"\"\n",
    "    template = \"\"\"\n",
    "Du bist ein erfahrener Sprachlernexperte und Pädagoge. Deine Aufgabe ist es, hochwertigen, lernzielorientierten Inhalt zu erstellen, der kulturell authentisch und didaktisch wertvoll ist.\n",
    "Generiere ausschließlich den gewünschten Inhalt unter Berücksichtigung der unten aufgeführten Anweisungen. Verzichte auf Einleitungen, Erklärungen oder Kommentare wie ‚Klar‘, ‚Hier ist dein Inhalt‘ usw., die nicht Teil der Anweisungen sind.\n",
    "**Behalte ein geordnetes, klares und schönes Design bei. Wenn du Aufzählungspunkte verwendest, setze jeden Aufzählungspunkt in eine neue Zeile. Vom Ausgabeformat dieses Prompts must du die Setzung der Zeilenumbrüche ('\\n') beachten.**\n",
    "Basierend auf dem generierten Inhalt über {topic} für das Niveau {level}, erstelle eine präzise Schreibaufgabe.\n",
    "\n",
    "GENERIERTER HAUPTINHALT ZUR REFERENZ:\n",
    "{main_content}\n",
    "\n",
    "AUFGABE: Erstelle klare Anweisungen für eine Schreibübung, die zum Hauptinhalt passt. Zeige Keine Lösungen für die Übung.\n",
    "\n",
    "FORMAT (GENAU BEFOLGEN!):\n",
    "**📝 SCHREIBAUFGABE**\n",
    "\n",
    "**Thema:** [Spezifisches Schreibthema basierend auf dem Hauptinhalt]\\n\\n\n",
    "\n",
    "**Anweisungen:**\\n\n",
    "• [Klare Aufgabenstellung]\\n\n",
    "• [Länge: X Wörter/Sätze]\\n\n",
    "• [Zu verwendende Grammatikstrukturen]\\n\n",
    "• [Erforderlicher Wortschatz]\\n\\n\n",
    "\n",
    "**Bewertungskriterien:**\\n\n",
    "• Grammatik und Rechtschreibung\\n\n",
    "• Verwendung des thematischen Vokabulars\\n\n",
    "• Struktur und Kohärenz\\n\n",
    "• Kreativität und Originalität\\n\\n\n",
    "\"\"\"\n",
    "\n",
    "    # Return prompt template with necessary variables\n",
    "    return PromptTemplate(\n",
    "        input_variables=[\"topic\", \"level\", \"main_content\"],\n",
    "        template=template\n",
    "    )\n",
    "\n",
    "def create_audio_comprehension_prompt():\n",
    "    \"\"\"\n",
    "    Create prompt template for audio comprehension exercise\n",
    "\n",
    "    Returns prompt template for audio exercise\n",
    "    \"\"\"\n",
    "    template = \"\"\"\n",
    "Du bist ein erfahrener Sprachlernexperte und Pädagoge. Deine Aufgabe ist es, hochwertigen, lernzielorientierten Inhalt zu erstellen, der kulturell authentisch und didaktisch wertvoll ist.\n",
    "Generiere ausschließlich den gewünschten Inhalt unter Berücksichtigung der unten aufgeführten Anweisungen. Verzichte auf Einleitungen, Erklärungen oder Kommentare wie ‚Klar‘, ‚Hier ist dein Inhalt‘ usw., die nicht Teil der Anweisungen sind.\n",
    "**Behalte ein geordnetes, klares und schönes Design bei. Wenn du Aufzählungspunkte verwendest, setze jeden Aufzählungspunkt in eine neue Zeile. Vom Ausgabeformat dieses Prompts must du die Setzung der Zeilenumbrüche ('\\n') beachten.**\n",
    "Erstelle einen Hörtext und Übungen für {topic} auf Niveau {level}.\n",
    "\n",
    "BEZUG ZUM HAUPTINHALT:\n",
    "{main_content}\n",
    "\n",
    "ERSTELLE:\n",
    "1. Einen Text zum Vorlesen (150-300 Wörter je nach Niveau). Generiere nur den reinen Text, keine Anweisungen zwischen Klammern bzgl. Stimmen, Musik usw. **Der Text muss neu sein, nicht gleich oder ähnlich wie der Hauptinhalt sein.** Beim Hörtext, benutze keine Emojis.\n",
    "2. Verständnisfragen zum Hörtext. Zeige keine Lösungen für die Übung.\n",
    "\n",
    "FORMAT (GENAU BEFOLGEN!):\n",
    "[Hier den vollständigen Hörtext - klar strukturiert, niveau-gerecht]\n",
    "\n",
    "\\n\\n**📋 VERSTÄNDNISFRAGEN**\\n\\n\n",
    "\n",
    "\\n1. [Frage 1]\\n\n",
    "   a) [Option A]\\n\n",
    "   b) [Option B]\\n\n",
    "   c) [Option C]\\n\\n\n",
    "\n",
    "2. [Frage 2]\\n\n",
    "   a) [Option A]\\n\n",
    "   b) [Option B]\\n\n",
    "   c) [Option C]\\n\\n\n",
    "\n",
    "3. [Frage 3 - Richtig/Falsch]\\n\\n\n",
    "\"\"\"\n",
    "\n",
    "    # Return prompt template with necessary variables\n",
    "    return PromptTemplate(\n",
    "        input_variables=[\"topic\", \"level\", \"main_content\"],\n",
    "        template=template\n",
    "    )\n",
    "\n",
    "def create_speaking_exercise_prompt():\n",
    "    \"\"\"\n",
    "    Create prompt template for speaking exercise instructions\n",
    "\n",
    "    Returns prompt template for speaking exercise\n",
    "    \"\"\"\n",
    "    template = \"\"\"\n",
    "Du bist ein erfahrener Sprachlernexperte und Pädagoge. Deine Aufgabe ist es, hochwertigen, lernzielorientierten Inhalt zu erstellen, der kulturell authentisch und didaktisch wertvoll ist.\n",
    "Generiere ausschließlich den gewünschten Inhalt unter Berücksichtigung der unten aufgeführten Anweisungen. Verzichte auf Einleitungen, Erklärungen oder Kommentare wie ‚Klar‘, ‚Hier ist dein Inhalt‘ usw., die nicht Teil der Anweisungen sind.\n",
    "**Behalte ein geordnetes, klares und schönes Design bei. Wenn du Aufzählungspunkte verwendest, setze jeden Aufzählungspunkt in eine neue Zeile (wenn du Unterteilungen innerhalb eines Aufzählungspunktes verwendest (mit diesem Symbol: - ), musst du jede Unterteilung ebenfalls in eine neue Zeile setzen.). Vom Ausgabeformat dieses Prompts must du die Setzung der Zeilenumbrüche ('\\n') beachten.**\n",
    "Erstelle eine Sprechaufgabe für {topic} auf Niveau {level}, die zum Hauptinhalt passt.\n",
    "\n",
    "HAUPTINHALT:\n",
    "{main_content}\n",
    "\n",
    "AUFGABE: Erstelle klare Anweisungen und Tipps für eine Sprechaufgabe, die zum Hauptinhalt passt. Zeige Keine Lösungen für die Übung.\n",
    "\n",
    "FORMAT (GENAU BEFOLGEN!):\n",
    "**🎤 SPRECHAUFGABE**\\n\n",
    "\n",
    "**Aufgabe:** [Klares Sprechthema]\\n\\n\n",
    "\n",
    "**Anweisungen:**\\n\n",
    "• **Sprechdauer:** [X Minuten]\\n\n",
    "• **Struktur:** [Einleitung, Hauptteil, Schluss]\\n\n",
    "• **Zu verwendende Redemittel:** [Liste wichtiger Phrasen]\\n\n",
    "• **Schwerpunkte:** [Grammatik/Vokabular-Fokus]\\n\\n\n",
    "\n",
    "**Tipps:**\\n\n",
    "• [Tipp 1 für gute Aussprache]\\n\n",
    "• [Tipp 2 für Struktur]\\n\n",
    "• [Tipp 3 für Flüssigkeit]\\n\\n\n",
    "\"\"\"\n",
    "\n",
    "    # Return prompt template with necessary variables\n",
    "    return PromptTemplate(\n",
    "        input_variables=[\"topic\", \"level\", \"main_content\"],\n",
    "        template=template\n",
    "    )\n",
    "\n",
    "def create_feedback_prompt():\n",
    "    \"\"\"\n",
    "    Create prompt template for exercise feedback\n",
    "\n",
    "    Returns prompt template for providing feedback\n",
    "    \"\"\"\n",
    "    template = \"\"\"\n",
    "Du bist ein erfahrener Sprachlernexperte und Pädagoge. Deine Aufgabe ist es, hochwertigen, lernzielorientierten Inhalt zu erstellen, der kulturell authentisch und didaktisch wertvoll ist.\n",
    "Generiere ausschließlich den gewünschten Inhalt unter Berücksichtigung der unten aufgeführten Anweisungen. Verzichte auf Einleitungen, Erklärungen oder Kommentare wie ‚Klar‘, ‚Hier ist dein Inhalt‘ usw., die nicht Teil der Anweisungen sind.\n",
    "**Behalte ein geordnetes, klares und schönes Design bei. Wenn du Aufzählungspunkte verwendest, setze jeden Aufzählungspunkt in eine neue Zeile. Vom Ausgabeformat dieses Prompts must du die Setzung der Zeilenumbrüche ('\\n') beachten.**\n",
    "Bewerte die folgende {exercise_type} eines {level}-Lerners zum Thema {topic}. **Bewerte nur die unterstehende ANTWORT DES LERNERS.** Achte darauf, dass der Lerner bei Lückentextübungen oder Multiple-Choice-Fragen (unter anderem) ggf. nicht die ganze Sätze aufgrund von Zeitsparnis schreiben wird.\n",
    "\n",
    "AUFGABENSTELLUNG:\n",
    "{task_instructions}\n",
    "\n",
    "______________________________________________\n",
    "ANTWORT DES LERNERS (**dies ist das Einzige, was vom Nutzer erstellt wurde und von dir bewertet werden muss.**):\n",
    "{user_response}\n",
    "______________________________________________\n",
    "\n",
    "Gib konstruktives, ermutigendes Feedback. Richte das Feedback direkt an den Lernenden. Halte das Feedback realistisch, professionell und an die Übung angepasst; akzeptiere keine unvollständigen oder schlechten Übungen.\n",
    "\n",
    "FORMAT (GENAU BEFOLGEN!):\n",
    "✅ FEEDBACK\n",
    "\n",
    "**Bewertung:** [Note/Punkte]\\n\\n\n",
    "\n",
    "**Stärken:**\\n\n",
    "• [Positive Aspekte]\\n\n",
    "• [Was gut gemacht wurde]\\n\\n\n",
    "\n",
    "**Verbesserungsvorschläge:**\\n\n",
    "• [Konstruktive Kritik]\\n\n",
    "• [Konkrete Verbesserungen]\\n\\n\n",
    "\n",
    "**Korrekturen:**\\n\n",
    "• [Fehler → Korrektur]\\n\n",
    "• [Fehler → Korrektur]\\n\\n\n",
    "\n",
    "**Nächste Schritte:**\\n\n",
    "• [Empfehlung für weiteres Lernen]\n",
    "\"\"\"\n",
    "\n",
    "    # Return prompt template with necessary variables\n",
    "    return PromptTemplate(\n",
    "        input_variables=[\"exercise_type\", \"level\", \"topic\", \"task_instructions\", \"user_response\"],\n",
    "        template=template\n",
    "    )\n",
    "\n",
    "def initialize_tts():\n",
    "    \"\"\"\n",
    "    Initialize Google Text-to-Speech client\n",
    "\n",
    "    Returns TTS client instance\n",
    "    \"\"\"\n",
    "    try:  # Start and return TTS client\n",
    "        client = texttospeech.TextToSpeechClient()\n",
    "        return client\n",
    "    except Exception as e:  # If it fails\n",
    "        print(f\"TTS initialization failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def initialize_stt():\n",
    "    \"\"\"\n",
    "    Initialize Google Speech-to-Text client\n",
    "\n",
    "    Returns STT client instance\n",
    "    \"\"\"\n",
    "    try:  # Start STT client\n",
    "        client = speech_v1.SpeechClient()\n",
    "        return client\n",
    "    except Exception as e:  # If it fails\n",
    "        print(f\"STT initialization failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def text_to_speech(text, tts_client):\n",
    "    \"\"\"\n",
    "    Convert text to speech using Google TTS\n",
    "\n",
    "    Args:\n",
    "        text (str): Text to convert\n",
    "        tts_client: Google TTS client\n",
    "\n",
    "    Returns:\n",
    "        bytes: Audio content in MP3 format\n",
    "    \"\"\"\n",
    "    if not tts_client:  # If no TTS client available\n",
    "        return None\n",
    "\n",
    "    try:  # If TTS client available\n",
    "        synthesis_input = texttospeech.SynthesisInput(text=text)  # Select text to be read\n",
    "\n",
    "        # Select voice\n",
    "        voice = texttospeech.VoiceSelectionParams(\n",
    "            language_code=\"de-DE\",\n",
    "            ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL\n",
    "        )\n",
    "\n",
    "        # Select encoding for the generated audio\n",
    "        audio_config = texttospeech.AudioConfig(\n",
    "            audio_encoding=texttospeech.AudioEncoding.MP3  # .mp3\n",
    "        )\n",
    "\n",
    "        # Generate audio\n",
    "        response = tts_client.synthesize_speech(\n",
    "            input=synthesis_input,\n",
    "            voice=voice,\n",
    "            audio_config=audio_config\n",
    "        )\n",
    "\n",
    "        return response.audio_content\n",
    "\n",
    "    except Exception as e:  # If audio generation fails\n",
    "        print(f\"TTS conversion failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def speech_to_text(audio_content, stt_client, sample_rate_hertz, topic: str):\n",
    "    \"\"\"\n",
    "    Convert speech to text using Google STT with an advanced configuration\n",
    "    \"\"\"\n",
    "    if not stt_client:  # If no STT client is available\n",
    "        return \"\"\n",
    "\n",
    "    try:  # If STT client is available\n",
    "        audio = speech_v1.RecognitionAudio(content=audio_content)  # Get audio\n",
    "\n",
    "        adaptation_client = speech_v1.AdaptationClient()\n",
    "        phrase_set = speech_v1.PhraseSet()\n",
    "\n",
    "        # The topic provides context to the model\n",
    "        phrase_set.phrases = [speech_v1.PhraseSet.Phrase(value=topic)]\n",
    "        phrase_set.boost = 20.0\n",
    "\n",
    "        adaptation = speech_v1.SpeechAdaptation(phrase_sets=[phrase_set])\n",
    "\n",
    "        # Configuration or voice recognition\n",
    "        config = speech_v1.RecognitionConfig(\n",
    "            encoding=speech_v1.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "            sample_rate_hertz=sample_rate_hertz,\n",
    "            language_code=\"de-DE\",\n",
    "            model=\"latest_long\",\n",
    "            enable_automatic_punctuation=True,\n",
    "            enable_word_time_offsets=False,\n",
    "            adaptation=adaptation  # Apply the topic hint\n",
    "        )\n",
    "\n",
    "        response = stt_client.recognize(config=config, audio=audio)  # Response from the recognition system\n",
    "        transcript = \"\".join(result.alternatives[0].transcript for result in response.results)  # Transcript generation joining all results\n",
    "\n",
    "        if not transcript.strip():  # If no transcript could be created\n",
    "            return \"NO_SPEECH_DETECTED\"\n",
    "\n",
    "        return transcript.strip()  # If transcript was created, return it\n",
    "\n",
    "    except Exception as e:  # If something failed\n",
    "        print(f\"STT conversion failed: {e}\")\n",
    "        return f\"STT_ERROR: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493,
     "referenced_widgets": [
      "74e6f48893854b6fb31d3bd2c5443cf1",
      "75a0af273f644ff19c22435b000e8340",
      "0c404b84295c4d36a6bc43df7b8cdf8a",
      "41f709d7a2b5401aa31d2e951f1e9587",
      "39e43bb86bae4b2fa5b777ef9a0eb97d",
      "d490e05a22a5433da161a6ca1d05af9c",
      "28cb9e09ff014fd694fd268b0f1cfdb3",
      "980e971eea6a4ff8b0ec8d26d186e5b9",
      "beacaf54a209465aa84e7d1ff8ae018f",
      "f406e9682877419c9b5c62d908e05e12",
      "a8183c6d1ef243ffa1f97f338d3475a2",
      "da9aa1a3f1a3491aa10868b981076585",
      "dafeff47241048f389e9457d18e1bc40",
      "05b0f585a3f74f4a81c5115272fc127b",
      "e2cb43f36ac643638ee111b4702fa1ad",
      "5c153b2645b646f2979278f7524385de",
      "0b9fbeb4058945caa8dd6b433fcc2b0d",
      "4ebae8139f1440a5ab0f8eac8ec5594f",
      "6ed948496fde4685b18ab8959333c4d2",
      "613c5248629b48ef8ac382edc03b5199",
      "f672930870c045009b7001fbb10655ad",
      "a0f44dd4263449128bfa0bb83564caaf",
      "a526ffa4290e47e2bf2eafd7a537b589",
      "034d5bc874b449ac9975d0e0486c85c0",
      "db56808ee37947e7897c601b16993ec5",
      "43e56d15c73d42d984da49ca2579c281",
      "c475e79b5a6c489eb09be62abff7bc2a",
      "038ca865b37b430fa4e7dc02d815c7df",
      "fbd5b4e43d7441ba90e5e603497c054e",
      "dbcdd3bbd7164fbfb37494386ce49a47",
      "4a92420d404e455fb5d7308ca08da6a4",
      "c65c9ae76a4d41c7936c16f9b49fa0e9",
      "2384bf112b3a4159b3efd89b4e1fa840",
      "e070370e0ede40699853a5fdf5a3cfde",
      "e7e1839faab240f3afb5f5a4f752b157",
      "895f2b6adc954e22bf57abf9b37fab57",
      "bd50a2befe714b08977c761399b2111f",
      "a9ab34999a7a4487b771d4df8c0cf995",
      "320b2a1767cf43a1958b9ed680ef3451",
      "2cdebd11d62d42d0b0d1f150189d2ff9",
      "4f8fee2ff37740159fdab3c2c1dfc11c",
      "c49b39a119664ec4bb07c42b46381461",
      "546e27df40b14496be395835c2f0cc10",
      "0d6143cd0e1a4c928829fcdf0cf30165",
      "beeedb8033364d508e20cc0da751467f",
      "3e1012eceba1499ca5432f13d90b9841",
      "6a171124b8194b1b997b3558a3ed6a8a",
      "d4257aea82014c0b9077409eb544a486",
      "fdac5a9f17ae4dcb925bd5f1ba65e59f",
      "73115b0fed164d059fae5e02cd82ab61",
      "d4b99a64fe8b47b1ad1ad477d27c283f",
      "5458e92ce9224849aae27d2678db07cd",
      "62731ae20ae046bd8f14b73b0a7a85ce",
      "14afeeb0ba4d4c3bb350860f02d8af1a",
      "d0df89738f5547b29aee968919c5fa5c",
      "066ffbc3e91b4b1095d1652e3fa69a0f",
      "448a1f12a2ef41528702deb8a738c663",
      "0b8e4c5dae0b4088be094616b752d254",
      "4e743bce29f24b58858035e7ccd3b24a",
      "aff9ad9d7ebf41fd8002d8871f0dca07",
      "ac3cc277f9fb40ac8e19b6d1c3e85f05",
      "2f5a43b57cf74282a6945013278c75f7",
      "5431aa2f3a9a4842918d8a3b42b6220b",
      "41380ff056b44792bfc1c480517438ca",
      "89fdea263deb48ccb7a459bb83c6e32a",
      "4396efdcddea431494cb6a23b8ad5c4c",
      "52a59c37dd834a98990fa14f62a5ea1e",
      "114fc691d9b44b9aa8bb647e0c8986d2",
      "b7f681e270b1409ea40e92ea15c8b296",
      "102e49fca00c4fe0ac7b4c4b6f2bb8c2",
      "94735889e68547e5b9f19e3dbd90afee",
      "1dd0067b8ade4231b93f5752655cd6a3",
      "07f6b220ba344151884f717d2ecc289f",
      "93d64cd0b7db475e98df9dd79205e339",
      "b3433c63f60f4eb686b26c80bffe20b5",
      "516ba92c219f46acb8ce8dc945a0d4ac",
      "ee994b7975264fc582e524591e3bfcfd",
      "564a67d7ad464a4caf0196108bccca54",
      "050afed7e93645fcb59c533ae2f1a4df",
      "d17914a19d8d472f82d733b9c3bf2e93",
      "6af4c02195ed46f086c3faeabbe7a47d",
      "ddd1257044b54830b5c0356a2eda90ff",
      "44020d6a67a9486d8cbdaa9598d29f41",
      "396f20ae08c04ce3b5980de8fa2abd56",
      "450f2d08af2f4bbaaff2afc0bc685997",
      "9b02d5000114435c9b5ac90818a508c5",
      "3b1569d022334d09beb348da46b4e969",
      "ca754f3b96b447d483ed463fdb5024e5",
      "94081160bc654e0e99af28e3c43a9c74",
      "1fdc9851b73949458a4214d242af8270",
      "1b508ff9cd8042c6964ad41796874e12",
      "17a4a43b90db4cc0992ad651e5b9ce93",
      "8a5d5d5c6e8d4eaab1fb53cc1284fea5",
      "4922a4464da142f4b46eccc2a0797acb",
      "8fde49d8ebe94424944ae111cca154cf",
      "31d7b7ceaa884b629c73107a84feeb65",
      "970e63fa84db4937bea4c661b18ec4a5",
      "7967ff1bc29441908c3820f7d083ab37",
      "6a1189a104b6418eb66bf74143d240e8",
      "a90d3ed3d1324fee8f8d1d6716e92a72",
      "45159b021cfd415c94eddf8ee64296d8",
      "9a81816d39cd4ee09ed522c5d915204c",
      "3ed7a0bcabd145898fc2b6c21dde1c98",
      "9ac46d2b5af940ca94061bfeadc659de",
      "2cd97c98a9a64d68bab2611aab426156",
      "1277f82f4d6d488db2fa1a34a4891a9e",
      "28299a5e1d2c4cd2bc9ae71a9ef0c820",
      "76cb0bbab7434e76a1564885e4e2595b",
      "d31047c483c94b5f89df74b17e556147",
      "1ba11403b9584bc38711e986ce5cd6be",
      "e848ec987a694c2884cf71f0a9fd3dc1",
      "20a0ab2eda46478aac1d84cf9cd99a66",
      "25958d85144443e3a332837a8a664373",
      "58e5c5e1d6bf47ac80c059cea1e03926",
      "c45c36f786594cf0845fbe808940c1ee",
      "bd86d848f53b4e66a46bfc8f704053a9",
      "329112416f454dc68fcf3dfac81bf58a",
      "dde6ca5c3b5345469ce949d3d622e20a",
      "45067de8693045b59a81260be02298d2",
      "0be314055e62484abf7ec6e4e7c492ed",
      "75b316ccb15d4746a355dc70d94d461a"
     ]
    },
    "id": "init_backend",
    "outputId": "858b793c-066e-454b-9015-db21709e1b4c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "74e6f48893854b6fb31d3bd2c5443cf1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da9aa1a3f1a3491aa10868b981076585"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a526ffa4290e47e2bf2eafd7a537b589"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e070370e0ede40699853a5fdf5a3cfde"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "beeedb8033364d508e20cc0da751467f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "066ffbc3e91b4b1095d1652e3fa69a0f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "52a59c37dd834a98990fa14f62a5ea1e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "564a67d7ad464a4caf0196108bccca54"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "94081160bc654e0e99af28e3c43a9c74"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a90d3ed3d1324fee8f8d1d6716e92a72"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e848ec987a694c2884cf71f0a9fd3dc1"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Initialize backend components\n",
    "\n",
    "embeddings = initialize_embeddings()  # Initialize embeddings\n",
    "vector_store = initialize_vector_store(embeddings)  # Connect to vector store\n",
    "llm1 = initialize_llm1()  # Start LLM 1 for exercises\n",
    "llm2 = initialize_llm2()  # Start LLM 2 for feedback\n",
    "\n",
    "if vector_store:  # If vector store connection is working\n",
    "    retriever = vector_store.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 3})  # Set retriever, return top 3 relevant documents\n",
    "else:  # If it is not working\n",
    "    retriever = None  # Continue app without retriever (without RAG)\n",
    "    print(\"Vector store connection failed, continuing without retrieval\")\n",
    "\n",
    "if llm1:  # If LLM 1 is working\n",
    "    # Initialize\n",
    "    prompt = create_prompt_template()  # Create main prompt template\n",
    "    writing_prompt = create_writing_exercise_prompt()  # Create writing prompt template\n",
    "    audio_prompt = create_audio_comprehension_prompt()  # Create audio prompt template\n",
    "    speaking_prompt = create_speaking_exercise_prompt()  # Create speaking prompt template\n",
    "else:  # If it is not working\n",
    "    raise RuntimeError(\"LLM initialization failed. Cannot continue\")  # Stop execution; app cannot be executed without LLM\n",
    "\n",
    "if llm2:  # If LLM 2 is working\n",
    "    # Initialize\n",
    "    feedback_prompt = create_feedback_prompt()  # Create feedback prompt template\n",
    "else:  # If it is not working\n",
    "    raise RuntimeError(\"LLM initialization failed. Cannot continue\")  # Stop execution; app cannot be executed without LLM\n",
    "\n",
    "# Initialize TTS and STT clients\n",
    "tts_client = initialize_tts()  # text-to-speech\n",
    "stt_client = initialize_stt()  # Speech-to-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "define_fastapi"
   },
   "outputs": [],
   "source": [
    "# Define the FastAPI backend application\n",
    "\n",
    "# FastAPI initialization with title and description of the project\n",
    "app_backend = FastAPI(title=\"KultuRAG API\", description=\"Cultural AI Language Learning Assistant with RAG\")\n",
    "\n",
    "# Define the data structures (Pydantic models) for incoming API requests using Pydantic\n",
    "class ContentRequest(BaseModel):\n",
    "    \"\"\"Defines the expected JSON structure for the main content generation request\"\"\"\n",
    "    thema: str\n",
    "    sprachniveau: str\n",
    "    inhaltstyp: str\n",
    "\n",
    "class FeedbackRequest(BaseModel):\n",
    "    \"\"\"Request structure for exercise feedback\"\"\"\n",
    "    exercise_type: str\n",
    "    level: str\n",
    "    topic: str\n",
    "    task_instructions: str\n",
    "    user_response: str\n",
    "\n",
    "class TTSRequest(BaseModel):\n",
    "    \"\"\"Request structure for text-to-speech\"\"\"\n",
    "    text: str\n",
    "\n",
    "class STTRequest(BaseModel):\n",
    "    \"\"\"Request structure for speech-to-text\"\"\"\n",
    "    audio_data: str\n",
    "    sample_rate: int\n",
    "    topic: str\n",
    "\n",
    "# API endpoints\n",
    "@app_backend.get(\"/\")\n",
    "def root():\n",
    "    \"\"\"\n",
    "    Root endpoint for basic connectivity checks\n",
    "\n",
    "    Provides a simple, welcoming message to confirm that the API server is running and accessible\n",
    "    \"\"\"\n",
    "    return {\"message\": \"KultuRAG Backend is running!\", \"status\": \"healthy\"}\n",
    "\n",
    "@app_backend.get(\"/health\")\n",
    "def health_check():\n",
    "    \"\"\"\n",
    "    Health check endpoint for monitoring the status of the services\n",
    "\n",
    "    This endpoint verifies the availability of components like the LLM and the vector store\n",
    "\n",
    "    Returns:\n",
    "        dict: A JSON object indicating the overall status and the status of individual components\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"status\": \"healthy\",\n",
    "        \"llm_available\": llm is not None,\n",
    "        \"vector_store_available\": vector_store is not None,\n",
    "    }\n",
    "\n",
    "@app_backend.post(\"/generate\")\n",
    "async def generate_content_exercises(request: ContentRequest):\n",
    "    \"\"\"\n",
    "\n",
    "    Main endpoint for generating the main learning content\n",
    "\n",
    "    This function manages the entire RAG process based on the user's request. It validates input, retrieves contextual data, and invokes the LLM to generate the final content\n",
    "\n",
    "    Args:\n",
    "        request (ContentRequest): A Pydantic model containing the topic, language level and content type\n",
    "\n",
    "    Raises:\n",
    "        HTTPException: 400 for invalid user input\n",
    "\n",
    "        HTTPException: 500 for internal errors during RAG or LLM processing\n",
    "\n",
    "    Returns:\n",
    "        dict: A JSON object containing the generated learning content\n",
    "    \"\"\"\n",
    "\n",
    "    # Input validation\n",
    "    is_valid, error_msg = validate_inputs(request.thema, request.sprachniveau, request.inhaltstyp)\n",
    "    if not is_valid:  # If not all elements are valid\n",
    "        raise HTTPException(status_code=400, detail=error_msg)  # Raise error\n",
    "\n",
    "    print(f\"Received request: {request.thema} | {request.sprachniveau} | {request.inhaltstyp}\")\n",
    "\n",
    "    # Retrieve examples from vector store - RAG\n",
    "    # Get examples from the Qdrant vector store\n",
    "    natural_examples = \"• Keine spezifischen Beispiele verfügbar.\"  # Standard example before doing the search in the vector database\n",
    "    if retriever:  # If retriever is working\n",
    "        try:\n",
    "            docs = retriever.invoke(request.thema)  # Retrieve examples of the desired topic\n",
    "            if docs:  # If some examples were found\n",
    "                natural_examples = \"\\n\".join([f\"• {doc.page_content}\" for doc in docs])  # substitute standard example for new examples\n",
    "        except Exception as e:  # If search failed\n",
    "            print(f\"Vector store query failed: {e}\")\n",
    "\n",
    "    # Get cultural context from Wikipedia\n",
    "    cultural_context = search_wikipedia_topic(request.thema)\n",
    "\n",
    "    # Generate content with LLM\n",
    "    try:\n",
    "        # Format prompt with variables\n",
    "        formatted_prompt = prompt.format(\n",
    "            topic=request.thema,\n",
    "            level=request.sprachniveau.lower(),\n",
    "            level_upper=request.sprachniveau.upper(),\n",
    "            content_type=request.inhaltstyp,\n",
    "            content_type_upper=request.inhaltstyp.upper(),\n",
    "            natural_examples=natural_examples,\n",
    "            cultural_context=cultural_context\n",
    "        )\n",
    "\n",
    "        # Generate content with the LLM 1\n",
    "        response = llm1.invoke(formatted_prompt)\n",
    "\n",
    "        return {\"content\": response}\n",
    "\n",
    "    except Exception as e:  # If generation fails\n",
    "        print(f\"LLM generation failed: {e}\")\n",
    "        raise HTTPException(status_code=500, detail=f\"Error generating content: {e}\")  # Raise exception\n",
    "\n",
    "@app_backend.post(\"/generate\")\n",
    "async def generate_content_feedback(request: ContentRequest):\n",
    "    \"\"\"\n",
    "    Main endpoint for generating the main learning content\n",
    "\n",
    "    This function manages the RAG process based on the user's request. It validates input, retrieves contextual data, and invokes the LLM to generate the final content\n",
    "\n",
    "    Args:\n",
    "        request (ContentRequest): A Pydantic model containing the topic, language level and content type\n",
    "\n",
    "    Raises:\n",
    "        HTTPException: 400 for invalid user input\n",
    "\n",
    "        HTTPException: 500 for internal errors during RAG or LLM processing\n",
    "\n",
    "    Returns:\n",
    "        dict: A JSON object containing the generated learning content\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    is_valid, error_msg = validate_inputs(request.thema, request.sprachniveau, request.inhaltstyp)\n",
    "    if not is_valid:  # If not all elements are valid\n",
    "        raise HTTPException(status_code=400, detail=error_msg)  # Raise error\n",
    "\n",
    "    print(f\"Received request: {request.thema} | {request.sprachniveau} | {request.inhaltstyp}\")\n",
    "\n",
    "    # Retrieve examples from vector store - RAG\n",
    "    # Get examples from the Qdrant vector store\n",
    "    natural_examples = \"Keine spezifischen Beispiele verfügbar\"  # Standard example before doing the search in the vector database\n",
    "    if retriever:  # If retriever is working\n",
    "        try:\n",
    "            docs = retriever.invoke(request.thema)  # Retrieve examples of the desired topic\n",
    "            if docs:  # If some documents were found\n",
    "                natural_examples = \"\\n\".join([f\"• {doc.page_content}\" for doc in docs])  # substitute standard example for new examples\n",
    "        except Exception as e:  # If search failed\n",
    "            print(f\"Vector store query failed: {e}\")\n",
    "\n",
    "    # Get cultural context from Wikipedia\n",
    "    cultural_context = search_wikipedia_topic(request.thema)\n",
    "\n",
    "    # Generate content with LLM\n",
    "    try:\n",
    "        # Format prompt with variables\n",
    "        formatted_prompt = prompt.format(\n",
    "            topic=request.thema,\n",
    "            level=request.sprachniveau.lower(),\n",
    "            level_upper=request.sprachniveau.upper(),\n",
    "            content_type=request.inhaltstyp,\n",
    "            content_type_upper=request.inhaltstyp.upper(),\n",
    "            natural_examples=natural_examples,\n",
    "            cultural_context=cultural_context\n",
    "        )\n",
    "\n",
    "        # Generate content with the LLM 2\n",
    "        response = llm2.invoke(formatted_prompt)\n",
    "\n",
    "        return {\"content\": response}\n",
    "\n",
    "    except Exception as e:  # If generation fails\n",
    "        print(f\"LLM generation failed: {e}\")\n",
    "        raise HTTPException(status_code=500, detail=f\"Error generating content: {e}\")  # Raise exception\n",
    "\n",
    "\n",
    "@app_backend.post(\"/generate_exercises\")\n",
    "async def generate_all_exercises(request: ContentRequest):\n",
    "    \"\"\"\n",
    "    Generate all exercise types based on main content\n",
    "\n",
    "    Returns all exercises together after generation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # First generate main content\n",
    "        main_content_response = await generate_content_exercises(request)  # Wait until content is generated\n",
    "        main_content = main_content_response[\"content\"]\n",
    "\n",
    "        # Generate writing exercise\n",
    "        writing_exercise = llm1.invoke(\n",
    "            writing_prompt.format(\n",
    "                topic=request.thema,\n",
    "                level=request.sprachniveau,\n",
    "                main_content=main_content\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Generate audio comprehension exercise\n",
    "        audio_exercise = llm1.invoke(\n",
    "            audio_prompt.format(\n",
    "                topic=request.thema,\n",
    "                level=request.sprachniveau,\n",
    "                main_content=main_content\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Generate speaking exercise\n",
    "        speaking_exercise = llm1.invoke(\n",
    "            speaking_prompt.format(\n",
    "                topic=request.thema,\n",
    "                level=request.sprachniveau,\n",
    "                main_content=main_content\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Return all generated content\n",
    "        return {\n",
    "            \"main_content\": main_content,\n",
    "            \"writing_exercise\": writing_exercise,\n",
    "            \"audio_exercise\": audio_exercise,\n",
    "            \"speaking_exercise\": speaking_exercise\n",
    "        }\n",
    "\n",
    "    except Exception as e:  # If generation failed\n",
    "        raise HTTPException(status_code=500, detail=f\"Exercise generation failed: {e}\")\n",
    "\n",
    "@app_backend.post(\"/feedback\")\n",
    "async def provide_feedback(request: FeedbackRequest):\n",
    "    \"\"\"\n",
    "    Provide feedback for user's exercise response\n",
    "    \"\"\"\n",
    "    try:\n",
    "        feedback = llm2.invoke(\n",
    "            feedback_prompt.format(\n",
    "                exercise_type=request.exercise_type,\n",
    "                level=request.level,\n",
    "                topic=request.topic,\n",
    "                task_instructions=request.task_instructions,\n",
    "                user_response=request.user_response\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return {\"feedback\": feedback}\n",
    "\n",
    "    except Exception as e:  # If generation failed\n",
    "        raise HTTPException(status_code=500, detail=f\"Feedback generation failed: {e}\")\n",
    "\n",
    "@app_backend.post(\"/tts\")\n",
    "async def text_to_speech_endpoint(request: TTSRequest):\n",
    "    \"\"\"\n",
    "    Convert text to speech\n",
    "    \"\"\"\n",
    "    try:\n",
    "        audio_content = text_to_speech(request.text, tts_client)  # Convertion\n",
    "        if audio_content:  # If conversion was successful\n",
    "            # Create and return audio file\n",
    "            audio_base64 = base64.b64encode(audio_content).decode('utf-8')\n",
    "            return {\"audio\": audio_base64}\n",
    "        else:  # If conversion failed\n",
    "            raise HTTPException(status_code=500, detail=\"TTS conversion failed\")\n",
    "\n",
    "    except Exception as e:  # If any error occured\n",
    "        raise HTTPException(status_code=500, detail=f\"TTS error: {e}\")\n",
    "\n",
    "@app_backend.post(\"/stt\")\n",
    "async def speech_to_text_endpoint(request: STTRequest):\n",
    "    \"\"\"\n",
    "    Convert speech to text\n",
    "    \"\"\"\n",
    "    try:\n",
    "        audio_bytes = base64.b64decode(request.audio_data)\n",
    "        # Pass the audio, sample rate and topic to the helper function\n",
    "        transcript = speech_to_text(audio_bytes, stt_client, request.sample_rate, request.topic)\n",
    "        return {\"transcript\": transcript}\n",
    "\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"STT error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNt-s1-64UPe"
   },
   "source": [
    "## 4. Frontend\n",
    "\n",
    "This section creates the user interface using Streamlit. The entire frontend code is written to a file named app.py.\n",
    "\n",
    "**Page Layout:** It configures the page title, icon, and layout. It also defines the CSS for styling the app's components.\n",
    "\n",
    "**User Interface:**\n",
    "* It creates input fields for the user to enter a topic, select a language level, and choose a content type.\n",
    "\n",
    "* The generated content is displayed in a tabbed interface, separating the exercises into reading, writing, listening and speaking.\n",
    "\n",
    "* It includes interactive elements like text areas for submitting answers, buttons to generate audio and a real-time audio recorder for the speaking exercises.\n",
    "\n",
    "**API Interaction:** The frontend sends requests to the FastAPI backend to generate content, get feedback and handle audio processing. It then displays the results returned by the backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "define_streamlit",
    "outputId": "c615f90d-f102-4330-acbf-708eb000382a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Writing app.py\n"
     ]
    }
   ],
   "source": [
    "# Define the Streamlit frontend application\n",
    "\n",
    "# Create the python script that Streamlit will run\n",
    "%%writefile app.py\n",
    "\n",
    "# These imports are also at the start of the notebook. Without them here, the cell cannot be executed correctly, because app.py does not have access to other cells\n",
    "# Keep imports here!\n",
    "import streamlit as st\n",
    "import requests, json, base64, av, io, queue, re\n",
    "from streamlit_webrtc import webrtc_streamer, WebRtcMode\n",
    "import streamlit.components.v1 as components\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "\n",
    "class AudioRecorder:\n",
    "    \"\"\"This class will process and save the audio frames from the browser\"\"\"\n",
    "    def __init__(self):\n",
    "        self._frames = []\n",
    "\n",
    "    def recv(self, frame: av.AudioFrame) -> av.AudioFrame:\n",
    "        self._frames.append(frame)\n",
    "        return frame\n",
    "\n",
    "    def get_frames(self):\n",
    "        return self._frames\n",
    "\n",
    "    def clear_frames(self):\n",
    "        self._frames = []\n",
    "\n",
    "# Page configuration\n",
    "st.set_page_config(\n",
    "    page_title=\"KultuRAG\",\n",
    "    page_icon=\"🌍\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"auto\"\n",
    ")\n",
    "\n",
    "# API URL is fixed to the local backend\n",
    "API_URL = \"http://localhost:8000\"\n",
    "\n",
    "# CSS for styling\n",
    "st.markdown(\"\"\"\n",
    "<style>\n",
    "    .main-header {\n",
    "        text-align: center;\n",
    "        padding: 1rem 0;\n",
    "        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);\n",
    "        color: white;\n",
    "        border-radius: 10px;\n",
    "        margin-bottom: 2rem;\n",
    "    }\n",
    "    .info-box {\n",
    "        background-color: #f0f2f6;\n",
    "        padding: 1rem;\n",
    "        border-radius: 10px;\n",
    "        margin: 1rem 0;\n",
    "    }\n",
    "    .success-box {\n",
    "        background-color: #d4edda; color: #155724;\n",
    "        padding: 1.5rem; border-radius: 10px; border: 1px solid #c3e6cb;\n",
    "        margin: 1rem 0;\n",
    "    }\n",
    "    .error-box {\n",
    "        background-color: #f8d7da; color: #721c24;\n",
    "        padding: 1rem; border-radius: 10px; border: 1px solid #f5c6cb;\n",
    "        margin: 1rem 0;\n",
    "    }\n",
    "    .exercise-box {\n",
    "        background-color: #f8f9fa;\n",
    "        padding: 1.5rem;\n",
    "        border-radius: 10px;\n",
    "        border: 2px solid #dee2e6;\n",
    "        margin: 1.5rem 0;\n",
    "    }\n",
    "    .feedback-box {\n",
    "        background-color: #e7f3ff;\n",
    "        padding: 1rem;\n",
    "        border-radius: 10px;\n",
    "        border: 1px solid #b3d9ff;\n",
    "        margin: 1rem 0;\n",
    "    }\n",
    "</style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# Initialize session state\n",
    "if 'generated_content' not in st.session_state:\n",
    "    st.session_state.generated_content = None\n",
    "if 'exercises' not in st.session_state:\n",
    "    st.session_state.exercises = None\n",
    "if 'audio_data' not in st.session_state:\n",
    "    st.session_state.audio_data = None\n",
    "if 'recorded_audio' not in st.session_state:\n",
    "    st.session_state.recorded_audio = None\n",
    "\n",
    "# Header\n",
    "st.markdown(\"\"\"\n",
    "<div class=\"main-header\">\n",
    "    <h1>🌍 KultuRAG - Cultural AI Language Learning Assistant</h1>\n",
    "    <p>Erlebe KI-generierte Inhalte basierend auf kulturellem Wissen</p>\n",
    "</div>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# Sidebar for health check\n",
    "st.sidebar.title(\"⚙️ Systemstatus\")\n",
    "if st.sidebar.button(\"🔍 Backend-Status prüfen\"):  # If option is chosen\n",
    "    try:\n",
    "        response = requests.get(f\"{API_URL}/health\", timeout=5)  # Get response of the backend API endpoint\n",
    "        if response.status_code == 200:  # If working\n",
    "            st.sidebar.success(\"✅ Backend verbunden!\")\n",
    "            st.sidebar.json(response.json())\n",
    "        else:  # If not working\n",
    "            st.sidebar.error(f\"❌ Backend antwortet nicht (Status: {response.status_code})\")\n",
    "    except Exception as e:  # If something else failed\n",
    "        st.sidebar.error(f\"❌ Verbindungsfehler: {e}\")\n",
    "st.sidebar.info(f\"Das Frontend ist fest mit dem lokalen Backend unter `{API_URL}` verbunden.\")\n",
    "\n",
    "\n",
    "# Main content\n",
    "col1, col2 = st.columns([2, 1])  # Columns\n",
    "\n",
    "# Column 1\n",
    "with col1:\n",
    "    st.markdown(\"### 📝 Lerninhalt erstellen\")  # Title\n",
    "    thema = st.text_input(\"✍️ Thema eingeben\", placeholder=\"z.B. Deutsche Küche, Oktoberfest...\")  # Text box for topic with instructions and examples\n",
    "    sprachniveau = st.selectbox(\"📚 Sprachniveau wählen\", options=[\"A1\", \"A2\", \"B1\", \"B2\", \"C1\", \"C2\"], index=2)  # Select box with options for language level\n",
    "    inhaltstyp = st.radio(\"🎭 Inhaltstyp wählen\", options=['Kurztext', 'Langtext', 'Geschichte', 'Märchen', 'Dialog',\n",
    "                   'Interview', 'Redewendung', 'Rolenspiel', 'Gedicht', 'Drama', 'Liedtext',\n",
    "                   'Online-Gespräch', 'Jugendsprache'], horizontal=True)  # Selecion of content generation type\n",
    "\n",
    "# Column 2\n",
    "with col2:\n",
    "    st.markdown(\"### 💡 Tipps\")  # Title\n",
    "    # Description box\n",
    "    st.markdown(\"\"\"\n",
    "    <div class=\"info-box\" style=\"color: black;\">\n",
    "    <strong>📋 Interessante Themen:</strong><br>\n",
    "    • Deutsche Traditionen<br>\n",
    "    • Städte und Regionen<br>\n",
    "    • Essen und Trinken<br>\n",
    "    • Kunst und Kultur<br>\n",
    "    </div>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# Generate Button to send inputs to the backend and generate response\n",
    "if st.button(\"🚀 Inhalt und Übungen generieren\", type=\"primary\", use_container_width=True):  # If user clicks on button\n",
    "    if not thema or len(thema.strip()) < 2:  # If there is no topic or topic is not valid\n",
    "        st.error(\"❌ Bitte gib ein gültiges Thema ein (mindestens 2 Zeichen)\")\n",
    "    else:  # If topic exists and is valid\n",
    "        with st.spinner('Generiere personalisierten Lerninhalt und interaktive Übungen...'):\n",
    "            try: # Content generation\n",
    "                # Get inputs\n",
    "                request_data = {\n",
    "                    \"thema\": thema.strip(),\n",
    "                    \"sprachniveau\": sprachniveau,\n",
    "                    \"inhaltstyp\": inhaltstyp\n",
    "                }\n",
    "\n",
    "                # Generate all content and exercises\n",
    "                response = requests.post(f\"{API_URL}/generate_exercises\", json=request_data, timeout=120)\n",
    "\n",
    "                if response.status_code == 200:  # If content was successfully generated\n",
    "                    data = response.json()\n",
    "                    st.session_state.generated_content = data\n",
    "                    st.session_state.exercises = {\n",
    "                        'thema': thema,\n",
    "                        'sprachniveau': sprachniveau,\n",
    "                        'inhaltstyp': inhaltstyp\n",
    "                    }\n",
    "                else:  # If content was not successfully generated\n",
    "                    error_detail = response.json().get(\"detail\", response.text)\n",
    "                    st.error(f\"Backend-Fehler: {error_detail}\")\n",
    "\n",
    "            except Exception as e:  # If something failed\n",
    "                st.error(f\"🚨 Fehler: {e}\")\n",
    "\n",
    "# Display generated content\n",
    "if st.session_state.generated_content:  # If content is available\n",
    "    data = st.session_state.generated_content\n",
    "\n",
    "    # Success info box\n",
    "    st.markdown(\"---\")\n",
    "    st.markdown(\"### Generierter Lerninhalt\")\n",
    "    st.markdown(f\"\"\"\n",
    "    <div class=\"success-box\">\n",
    "        <strong>📊 Details:</strong><br>\n",
    "        🎯 Thema: {st.session_state.exercises['thema']}<br>\n",
    "        📚 Niveau: {st.session_state.exercises['sprachniveau']}<br>\n",
    "        📝 Typ: {st.session_state.exercises['inhaltstyp']}\n",
    "    </div>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "    # Create tabs for the different content sections\n",
    "    tab1, tab2, tab3, tab4 = st.tabs([\"📖 Leseverstehen\", \"✍️ Schreibübung\",\n",
    "                                             \"🎧 Hörübung\", \"🎤 Sprechübung\"])\n",
    "\n",
    "    # Tab 1: Main Content - Leseverstehen\n",
    "    with tab1:\n",
    "        st.markdown(data.get(\"main_content\", \"\"))\n",
    "\n",
    "        # Add feedback button for submitting existing exercise\n",
    "        st.markdown(\"### 📝 Übung einreichen\")\n",
    "        # Get exercise from user\n",
    "        original_exercise_answer = st.text_area(\"Deine Antwort zur Übung:\",\n",
    "                                               key=\"original_exercise\",\n",
    "                                               height=150)\n",
    "        # Show disclaimer about the possibility to redo the exercise after submitting it\n",
    "        st.markdown(\"<small style='color: #666;'>💡 Hinweis: Du kannst die Übung nach dem Absenden jederzeit erneut bearbeiten.</small>\",\n",
    "        unsafe_allow_html=True)\n",
    "\n",
    "        if st.button(\"Übung korrigieren\", key=\"correct_original\"):  # If user clicks on button\n",
    "            if original_exercise_answer:  # If user did the exercise\n",
    "                with st.spinner(\"Korrigiere Übung...\"):\n",
    "                    # Get data\n",
    "                    try:\n",
    "                        feedback_request = {\n",
    "                            \"exercise_type\": \"Übung\",\n",
    "                            \"level\": st.session_state.exercises['sprachniveau'],\n",
    "                            \"topic\": st.session_state.exercises['thema'],\n",
    "                            \"task_instructions\": \"Siehe Übung im Hauptinhalt\",\n",
    "                            \"user_response\": original_exercise_answer\n",
    "                        }\n",
    "\n",
    "                        # Generate feedback\n",
    "                        feedback_response = requests.post(f\"{API_URL}/feedback\",\n",
    "                                                         json=feedback_request,\n",
    "                                                         timeout=30)\n",
    "\n",
    "                        if feedback_response.status_code == 200:  # If feedback was generated\n",
    "                            feedback_data = feedback_response.json()\n",
    "                            # Show feedback\n",
    "                            st.markdown(f\"\"\"\n",
    "                            <div class=\"feedback-box\" style=\"color: black;\">\n",
    "                            {feedback_data['feedback']}\n",
    "                            </div>\n",
    "                            \"\"\", unsafe_allow_html=True)\n",
    "                    except Exception as e:  # If something failed\n",
    "                        st.error(f\"Fehler beim Feedback: {e}\")\n",
    "            else:  # If user did not do the exercise\n",
    "                st.warning(\"Bitte gib erst eine Antwort ein.\")\n",
    "\n",
    "    # Tab 2: Writing Exercise\n",
    "    with tab2:\n",
    "        st.markdown(data.get(\"writing_exercise\", \"\"))\n",
    "\n",
    "        # Text input for writing exercise\n",
    "        st.markdown(\"### ✍️ Dein Text\")\n",
    "        writing_input = st.text_area(\"Schreibe hier deinen Text:\",\n",
    "                                    key=\"writing_input\",\n",
    "                                    height=200)\n",
    "        # Show disclaimer about the possibility to redo the exercise after submitting it\n",
    "        st.markdown(\"<small style='color: #666;'>💡 Hinweis: Du kannst die Übung nach dem Absenden jederzeit erneut bearbeiten.</small>\",\n",
    "        unsafe_allow_html=True)\n",
    "\n",
    "        if st.button(\"Text einreichen\", key=\"submit_writing\"):  # If user clicks on button\n",
    "            if writing_input:  # If user did the exercise\n",
    "                with st.spinner(\"Analysiere deinen Text...\"):\n",
    "                    # Get data\n",
    "                    try:\n",
    "                        feedback_request = {\n",
    "                            \"exercise_type\": \"Schreibübung\",\n",
    "                            \"level\": st.session_state.exercises['sprachniveau'],\n",
    "                            \"topic\": st.session_state.exercises['thema'],\n",
    "                            \"task_instructions\": data.get(\"writing_exercise\", \"\"),\n",
    "                            \"user_response\": writing_input\n",
    "                        }\n",
    "\n",
    "                        # Generate response\n",
    "                        feedback_response = requests.post(f\"{API_URL}/feedback\",\n",
    "                                                         json=feedback_request,\n",
    "                                                         timeout=30)\n",
    "\n",
    "                        if feedback_response.status_code == 200:  # If feedback was generated\n",
    "                            feedback_data = feedback_response.json()\n",
    "                            # Show feedback\n",
    "                            st.markdown(f\"\"\"\n",
    "                            <div class=\"feedback-box\" style=\"color: black;\">\n",
    "                            {feedback_data['feedback']}\n",
    "                            </div>\n",
    "                            \"\"\", unsafe_allow_html=True)\n",
    "                    except Exception as e:  # If something failed\n",
    "                        st.error(f\"Fehler beim Feedback: {e}\")\n",
    "            else:  # If user did not do the exercise\n",
    "                st.warning(\"Bitte schreibe erst einen Text.\")\n",
    "\n",
    "    # Tab 3: Audio Comprehension\n",
    "    with tab3:\n",
    "        audio_content = data.get(\"audio_exercise\", \"\") # Get audio content\n",
    "        audio_text = \"\"\n",
    "        comprehension_questions = \"\"\n",
    "\n",
    "        # Split content into audio script and questions\n",
    "        # Define all possible separators\n",
    "        separators = [\n",
    "            \"**📋 VERSTÄNDNISFRAGEN**\",\n",
    "            \"*📋 VERSTÄNDNISFRAGEN*\",\n",
    "            \"📋 VERSTÄNDNISFRAGEN\",\n",
    "            \"**VERSTÄNDNISFRAGEN**\",\n",
    "            \"*VERSTÄNDNISFRAGEN*\",\n",
    "            \"VERSTÄNDNISFRAGEN\",\n",
    "            \"Verständnisfragen\"\n",
    "        ]\n",
    "\n",
    "        found_separator = None  # Save here the found separator\n",
    "        for sep in separators:\n",
    "            if sep in audio_content:\n",
    "                found_separator = sep\n",
    "                break  # Stop searching once a separator is found\n",
    "\n",
    "        if found_separator:  # If a separator was found\n",
    "            # Split the content\n",
    "            parts = audio_content.split(found_separator, 1)\n",
    "            audio_text = parts[0].strip()\n",
    "            comprehension_questions = found_separator + parts[1].strip()\n",
    "        else:  # If no separator is found after checking all possibilities\n",
    "            audio_text = audio_content\n",
    "            comprehension_questions = \"\"  # Ensure questions are empty if not found\n",
    "            st.warning(\"Ich konnte die Verständnisfragen nicht vom Hörtext trennen\")\n",
    "\n",
    "        # Generate audio button\n",
    "        if audio_text:\n",
    "            if st.button(\"🔊 Audio für den Hörtext generieren\", key=\"generate_audio\"):\n",
    "                with st.spinner(\"Generiere Audio...\"):\n",
    "                    try:\n",
    "                        # Clean the text of markdown symbols (*, #, etc.) before sending\n",
    "                        cleaned_text = re.sub(r'[*#]', '', audio_text)\n",
    "\n",
    "                        # Generate speech using the cleaned text\n",
    "                        tts_request = {\"text\": cleaned_text}  # Sends clean text\n",
    "                        tts_response = requests.post(f\"{API_URL}/tts\", json=tts_request, timeout=60)\n",
    "\n",
    "                        if tts_response.status_code == 200:  # If speech was successfully generated\n",
    "                            audio_data = tts_response.json()[\"audio\"]\n",
    "                            st.session_state.audio_data = audio_data\n",
    "                            st.success(\"Audio erfolgreich generiert!\")\n",
    "                        else:\n",
    "                            st.error(f\"Fehler bei Audio-Generierung: {tts_response.text}\")\n",
    "                    except Exception as e:  # If speech was not successfully generated\n",
    "                        st.error(f\"Fehler bei Audio-Generierung: {e}\")\n",
    "\n",
    "        # Play audio if available\n",
    "        if st.session_state.get('audio_data'):  # If audio exists\n",
    "            audio_bytes = base64.b64decode(st.session_state.audio_data)\n",
    "            st.audio(audio_bytes, format='audio/mp3')\n",
    "            if st.button(\"Audio-Player entfernen\", key=\"clear_audio\"):\n",
    "                st.session_state.audio_data = None\n",
    "                st.rerun()\n",
    "\n",
    "        st.markdown(\"---\")\n",
    "        # Display questions permanently\n",
    "        if comprehension_questions:\n",
    "            st.markdown(comprehension_questions)\n",
    "\n",
    "        # Show transcription in an expander\n",
    "        with st.expander(\"📖 Transkription des Hörtextes anzeigen\"):\n",
    "            st.markdown(audio_text if audio_text else \"Kein Transkript verfügbar.\")\n",
    "\n",
    "        # Answer input for comprehension questions\n",
    "        st.markdown(\"### 📋 Deine Antworten\")\n",
    "        audio_answers = st.text_area(\"Beantworte die Verständnisfragen:\", key=\"audio_answers\", height=150)\n",
    "        # Show disclaimer about the possibility to redo the exercise after submitting it\n",
    "        st.markdown(\"<small style='color: #666;'>💡 Hinweis: Du kannst die Übung nach dem Absenden jederzeit erneut bearbeiten.</small>\", unsafe_allow_html=True)\n",
    "\n",
    "        if st.button(\"Antworten einreichen\", key=\"submit_audio\"):  # If user clicks on button\n",
    "            if audio_answers:  # If user did the exercise\n",
    "                with st.spinner(\"Korrigiere Antworten...\"):\n",
    "                    try:\n",
    "                        # Get inputs\n",
    "                        feedback_request = {\n",
    "                            \"exercise_type\": \"Hörverständnis\",\n",
    "                            \"level\": st.session_state.exercises['sprachniveau'],\n",
    "                            \"topic\": st.session_state.exercises['thema'],\n",
    "                            \"task_instructions\": comprehension_questions,  # Now correctly sends only the questions\n",
    "                            \"user_response\": audio_answers\n",
    "                        }\n",
    "\n",
    "                        # Generate feedback\n",
    "                        feedback_response = requests.post(f\"{API_URL}/feedback\", json=feedback_request, timeout=30)\n",
    "\n",
    "                        if feedback_response.status_code == 200:  # If feedback was successfully generated\n",
    "                            feedback_data = feedback_response.json()\n",
    "                            # Show feedback\n",
    "                            st.markdown(f\"<div class=\\\"feedback-box\\\" style=\\\"color: black;\\\">{feedback_data['feedback']}</div>\", unsafe_allow_html=True)\n",
    "                        else:\n",
    "                            st.error(f\"Feedback-Fehler: {feedback_response.text}\")\n",
    "                    except Exception as e:  # If something failed\n",
    "                        st.error(f\"Fehler beim Feedback: {e}\")\n",
    "            else:  # If user did not do the exercise\n",
    "                st.warning(\"Bitte beantworte erst die Fragen.\")\n",
    "\n",
    "    # Tab 4: Speaking Exercise\n",
    "    with tab4:\n",
    "        st.markdown(data.get(\"speaking_exercise\", \"\"))\n",
    "\n",
    "        # Audio recording section\n",
    "        st.markdown(\"### 🎤 Sprachaufnahme\")\n",
    "\n",
    "        # Initiate recorder if it is not already initiated\n",
    "        if \"audio_recorder\" not in st.session_state:\n",
    "            st.session_state.audio_recorder = AudioRecorder()\n",
    "\n",
    "        # Create interface showing speaking process\n",
    "        webrtc_ctx = webrtc_streamer(\n",
    "            key=\"speaking-exercise\",\n",
    "            mode=WebRtcMode.SENDONLY,\n",
    "            audio_frame_callback=st.session_state.audio_recorder.recv,\n",
    "            media_stream_constraints={\"video\": False, \"audio\": True},\n",
    "        )\n",
    "\n",
    "        # Start interface\n",
    "        if webrtc_ctx.state.playing:\n",
    "            st.info(\"🎤 Aufnahme läuft... Klicke auf 'Stop', um zu beenden.\")\n",
    "\n",
    "        if not webrtc_ctx.state.playing:\n",
    "          audio_frames = st.session_state.audio_recorder.get_frames()\n",
    "          if audio_frames and \"recorded_audio_info\" not in st.session_state:\n",
    "              with st.spinner(\"Verarbeite Aufnahme...\"):\n",
    "                  # Get the sample rate and channel info from the first frame.\n",
    "                  sample_rate = audio_frames[0].sample_rate\n",
    "                  sample_width = audio_frames[0].format.bits // 8\n",
    "\n",
    "                  # Create an empty AudioSegment to build the full audio.\n",
    "                  sound = AudioSegment.empty()\n",
    "\n",
    "                  # Append each audio frame to the master AudioSegment.\n",
    "                  # pydub handles the conversion from raw bytes correctly.\n",
    "                  for frame in audio_frames:\n",
    "                      sound += AudioSegment(\n",
    "                          data=frame.to_ndarray().tobytes(),\n",
    "                          sample_width=sample_width,\n",
    "                          frame_rate=sample_rate,\n",
    "                          channels=len(frame.layout.channels)\n",
    "                      )\n",
    "\n",
    "                  # Export the final combined audio to a WAV format in memory.\n",
    "                  buffer = io.BytesIO()\n",
    "                  # Convert to mono and then export\n",
    "                  sound.set_channels(1).export(buffer, format=\"wav\")\n",
    "\n",
    "                  # Store the correct WAV bytes and sample rate in the session state.\n",
    "                  st.session_state.recorded_audio_info = {\"bytes\": buffer.getvalue(), \"rate\": sample_rate}\n",
    "                  st.session_state.audio_recorder.clear_frames()\n",
    "                  st.rerun()\n",
    "\n",
    "        if \"recorded_audio_info\" in st.session_state:  # If audio was recorded\n",
    "            st.success(\"✔️ Aufnahme abgeschlossen.\")\n",
    "            # Play back the audio from the stored bytes\n",
    "            st.audio(st.session_state.recorded_audio_info[\"bytes\"], format=\"audio/wav\")\n",
    "\n",
    "            # Show two options: submit audio and delete\n",
    "            col_submit, col_delete = st.columns(2)\n",
    "            with col_submit:  # Submit option\n",
    "                if st.button(\"✔️ Aufnahme zur Auswertung senden\", use_container_width=True):  # If user clicks on submit\n",
    "                    with st.spinner(\"Transkribere und bewerte deine Aufnahme...\"):\n",
    "                        try:\n",
    "                            # Get both bytes and rate from session state\n",
    "                            recorded_info = st.session_state.recorded_audio_info\n",
    "                            b64_audio = base64.b64encode(recorded_info[\"bytes\"]).decode()\n",
    "\n",
    "                            # Send the audio and the correct sample rate to the backend\n",
    "                            stt_request = {\n",
    "                                \"audio_data\": b64_audio,\n",
    "                                \"sample_rate\": recorded_info[\"rate\"],\n",
    "                                \"topic\": st.session_state.exercises['thema']\n",
    "                            }\n",
    "                            stt_response = requests.post(f\"{API_URL}/stt\", json=stt_request, timeout=60)\n",
    "\n",
    "                            if stt_response.status_code == 200:\n",
    "                                transcript = stt_response.json()[\"transcript\"]\n",
    "                                if not transcript:\n",
    "                                    st.warning(\"Konnte nichts aus der Aufnahme transkribieren. Bitte sprich lauter und versuche es erneut.\")\n",
    "                                else:\n",
    "                                    st.info(f\"**Transkript deiner Aufnahme:**\\n\\n> {transcript}\")\n",
    "                                    feedback_request = {\n",
    "                                        \"exercise_type\": \"Sprechübung\",\n",
    "                                        \"level\": st.session_state.exercises['sprachniveau'],\n",
    "                                        \"topic\": st.session_state.exercises['thema'],\n",
    "                                        \"task_instructions\": data.get(\"speaking_exercise\", \"\"),\n",
    "                                        \"user_response\": transcript\n",
    "                                    }\n",
    "                                    feedback_response = requests.post(f\"{API_URL}/feedback\", json=feedback_request, timeout=30)\n",
    "                                    if feedback_response.status_code == 200:\n",
    "                                        feedback_data = feedback_response.json()\n",
    "                                        st.markdown(f\"<div class=\\\"feedback-box\\\" style=\\\"color: black;\\\">{feedback_data['feedback']}</div>\", unsafe_allow_html=True)\n",
    "                                    else:\n",
    "                                        st.error(f\"Feedback-Fehler: {feedback_response.text}\")\n",
    "                            else:\n",
    "                                st.error(f\"Fehler bei der Transkription: {stt_response.text}\")\n",
    "                        except Exception as e:\n",
    "                            st.error(f\"Ein Fehler ist aufgetreten: {e}\")\n",
    "\n",
    "            with col_delete:  # Button to delete recorded audio\n",
    "                if st.button(\"🗑️ Aufnahme löschen\", use_container_width=True):  # If user clicks on it\n",
    "                    # Clear the processed audio info if it exists\n",
    "                    if \"recorded_audio_info\" in st.session_state:\n",
    "                        del st.session_state.recorded_audio_info\n",
    "\n",
    "                    # Also clear any raw frames from the recorder object\n",
    "                    st.session_state.audio_recorder.clear_frames()\n",
    "\n",
    "                    st.rerun()\n",
    "\n",
    "        st.markdown(\"---\")\n",
    "        # Alternative: Manual text input for speaking exercise\n",
    "        st.markdown(\"### 📝 Alternative: Text eingeben\")\n",
    "        speaking_text = st.text_area(\"Gib hier ein, was du sagen würdest (falls die Aufnahme nicht funktioniert):\",\n",
    "                                    key=\"speaking_text\", height=150)\n",
    "\n",
    "        if st.button(\"Text zur Auswertung senden\", key=\"submit_speaking_text\"):  # Button to send text to be corrected\n",
    "            if speaking_text:  # If user introduced a text\n",
    "                with st.spinner(\"Analysiere deine Antwort...\"):\n",
    "                    try:\n",
    "                        feedback_request = {\n",
    "                            \"exercise_type\": \"Sprechübung (als Text)\",\n",
    "                            \"level\": st.session_state.exercises['sprachniveau'],\n",
    "                            \"topic\": st.session_state.exercises['thema'],\n",
    "                            \"task_instructions\": data.get(\"speaking_exercise\", \"\"),\n",
    "                            \"user_response\": speaking_text\n",
    "                        }\n",
    "                        feedback_response = requests.post(f\"{API_URL}/feedback\", json=feedback_request, timeout=30)  # Generate feedback\n",
    "                        if feedback_response.status_code == 200:  # If feedback was generated\n",
    "                            feedback_data = feedback_response.json()\n",
    "                            st.markdown(f\"<div class=\\\"feedback-box\\\" style=\\\"color: black;\\\">{feedback_data['feedback']}</div>\", unsafe_allow_html=True)\n",
    "                        else:  # If feedback was not generated\n",
    "                             st.error(f\"Feedback-Fehler: {feedback_response.text}\")\n",
    "                    except Exception as e:  # If there was an error\n",
    "                        st.error(f\"Fehler beim Feedback: {e}\")\n",
    "            else:  # If user introduced no text\n",
    "                st.warning(\"Bitte gib erst einen Text ein.\")\n",
    "\n",
    "# Footer\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"\"\"\n",
    "<div style=\"text-align: center; color: #666; padding: 1rem;\">\n",
    "    🤖 Powered by KultuRAG AI • Made with ❤️ by Alberto Sánchez\n",
    "    <br><br>\n",
    "    <small style=\"color: white;\">⚠️ This app provides AI-generated learning content. While we strive for accuracy and educational value, the material may contain errors or limitations.\n",
    "    The app is not a substitute for qualified language instruction. Please use with critical judgment ⚠️</small>\n",
    "</div>\n",
    "\"\"\", unsafe_allow_html=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXePEOiI4ibA"
   },
   "source": [
    "## 5. Servers\n",
    "\n",
    "This final section launches the application.\n",
    "\n",
    "**Server Threads:** It starts the FastAPI backend and the Streamlit frontend on separate threads, allowing them to run simultaneously.\n",
    "\n",
    "**Ngrok Tunnel:** It uses ngrok to create a public URL that forwards to the Streamlit frontend. This makes the application running inside the Google Colab notebook accessible on the internet.\n",
    "\n",
    "**Keep-Alive:** A final cell runs an infinite loop to keep the Colab session active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "start_servers",
    "outputId": "e5d0d7ea-9a91-49fa-cabf-47f2d3122367"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting FastAPI backend on port 8000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:     Started server process [414]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting Streamlit frontend on port 8501\n",
      "KultuRAG app is live\n",
      "Public URL: NgrokTunnel:
     ]
    }
   ],
   "source": [
    "# Start servers and launch ngrok tunnel\n",
    "\n",
    "# Kill any previous ngrok tunnel\n",
    "ngrok.kill()\n",
    "\n",
    "# Set ngrok auth token\n",
    "ngrok.set_auth_token(ngrok_auth_token)\n",
    "\n",
    "# Function to run FastAPI backend\n",
    "def run_fastapi():\n",
    "    uvicorn.run(app_backend, host=\"0.0.0.0\", port=8000)\n",
    "\n",
    "# Function to run Streamlit frontend\n",
    "def run_streamlit():\n",
    "    os.system(\"streamlit run app.py --server.port 8501 --server.headless true\")\n",
    "\n",
    "# Start both servers in background threads\n",
    "fastapi_thread = threading.Thread(target=run_fastapi, daemon=True)  # Backend\n",
    "streamlit_thread = threading.Thread(target=run_streamlit, daemon=True)  # Frontend\n",
    "\n",
    "print(\"Starting FastAPI backend on port 8000\")\n",
    "fastapi_thread.start()\n",
    "time.sleep(5)  # Give backend time to start\n",
    "\n",
    "print(\"Starting Streamlit frontend on port 8501\")\n",
    "streamlit_thread.start()\n",
    "time.sleep(5)  # Give frontend time to start\n",
    "\n",
    "# Create a public ngrok tunnel to the Streamlit port\n",
    "public_url = ngrok.connect(8501)  # Static domain automatically asigned by ngrok\n",
    "print(\"KultuRAG app is live\")\n",
    "print(f\"Public URL: {public_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "keep_alive",
    "outputId": "7885d508-193f-4db8-cd13-e26e1dde8bd9"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "App is running. This cell will keep the Colab session alive\n"
     ]
    }
   ],
   "source": [
    "# Keep the notebook running to avoid that the server stops quickly\n",
    "\n",
    "print(\"App is running. This cell will keep the Colab session alive\")\n",
    "try:\n",
    "    while True:\n",
    "        time.sleep(3600)  # Keep alive for an hour at a time\n",
    "        print(\"Still alive\")\n",
    "except KeyboardInterrupt:  # If execution is interrupted by the user\n",
    "    print(\"\\nShutting down servers and ngrok tunnel\")\n",
    "    ngrok.kill()  # Stop execution\n",
    "    print(\"Shutdown complete\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}