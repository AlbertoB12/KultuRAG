{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title_cell"
   },
   "source": [
    "# KultuRAG: Cultural AI Language Learning Assistant with RAG\n",
    "# Combined Frontend & Backend\n",
    "\n",
    "This notebook runs the entire KultuRAG application. It starts a FastAPI backend and a Streamlit frontend, exposing them through a single public URL using ngrok.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Run all the cells in order\n",
    "2.  The final cell will provide a public ngrok URL\n",
    "3.  Click the URL to open your fully functional application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rcs_hT4ivsiz"
   },
   "source": [
    "## 1. Install and import packages / Project configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "install_deps",
    "outputId": "22566f57-96c8-442c-c10d-702eef082779"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m337.3/337.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m216.9/216.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m189.4/189.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.5/35.5 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 45.0.6 which is incompatible.\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  libportaudio2\n",
      "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
      "Need to get 65.3 kB of archives.\n",
      "After this operation, 223 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudio2 amd64 19.6.0-1.1 [65.3 kB]\n",
      "Fetched 65.3 kB in 0s (308 kB/s)\n",
      "Selecting previously unselected package libportaudio2:amd64.\n",
      "(Reading database ... 126371 files and directories currently installed.)\n",
      "Preparing to unpack .../libportaudio2_19.6.0-1.1_amd64.deb ...\n",
      "Unpacking libportaudio2:amd64 (19.6.0-1.1) ...\n",
      "Setting up libportaudio2:amd64 (19.6.0-1.1) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Install packages\n",
    "!pip -q install fastapi uvicorn pydantic pyngrok streamlit requests langchain-google-vertexai langchain-qdrant langchain-huggingface\n",
    "!pip -q install langchain wikipedia google-cloud-aiplatform google-auth streamlit-webrtc pydub google-cloud-texttospeech google-cloud-speech\n",
    "!apt-get install -y libportaudio2"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Authentication\n",
    "import os\n",
    "from google.colab import auth, userdata\n",
    "\n",
    "# Set the application default credentials for all Python libraries\n",
    "!gcloud auth application-default login\n",
    "\n",
    "# Set the project ID\n",
    "project_ID = userdata.get('gcloud_project')\n",
    "!gcloud config set project {project_ID}\n",
    "os.environ[\"GCLOUD_PROJECT\"] = project_ID\n",
    "\n",
    "# Standard Colab auth for full integration\n",
    "auth.authenticate_user(project_id=project_ID)\n",
    "\n",
    "# Link the credentials to project for billing quota\n",
    "!gcloud auth application-default set-quota-project {project_ID}"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Iu9UWSWCXTZ",
    "outputId": "f1b64909-dc06-432a-9550-0e1040eb61e3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Go to the following link in your browser, and complete the sign-in prompts:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fapplicationdefaultauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=9RN7hVWGop5e9UjKvwKOuuEtY0zBxn&prompt=consent&token_usage=remote&access_type=offline&code_challenge=QK07DGl284dJdhusx2uCQGwwSKpxDlGhSIRL0MZ0FZA&code_challenge_method=S256\n",
      "\n",
      "Once finished, enter the verification code provided in your browser: 4/0AVMBsJhOMOpLudY_VVCqzvVjlOvTqIWMi3sliZB9LWKjLsu8UooAKzi6194JYS15pbVrBw\n",
      "\n",
      "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
      "\n",
      "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
      "\u001b[1;33mWARNING:\u001b[0m \n",
      "Cannot find a quota project to add to ADC. You might receive a \"quota exceeded\" or \"API not enabled\" error. Run $ gcloud auth application-default set-quota-project to add a quota project.\n",
      "\u001b[1;33mWARNING:\u001b[0m Your active project does not match the quota project in your local Application Default Credentials file. This might result in unexpected quota issues.\n",
      "\n",
      "To update your Application Default Credentials quota project, use the `gcloud auth application-default set-quota-project` command.\n",
      "Updated property [core/project].\n",
      "\n",
      "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
      "\n",
      "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
      "\n",
      "Quota project \"spherical-treat-466107-r3\" was added to ADC which can be used by Google client libraries for billing and quota. Note that some services may still bill the project owning the resource.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "import_and_auth",
    "outputId": "64499bd8-3a06-41e4-9bbe-84602b59cc77"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:300: SyntaxWarning: invalid escape sequence '\\('\n",
      "  m = re.match('([su]([0-9]{1,2})p?) \\(([0-9]{1,2}) bit\\)$', token)\n",
      "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:301: SyntaxWarning: invalid escape sequence '\\('\n",
      "  m2 = re.match('([su]([0-9]{1,2})p?)( \\(default\\))?$', token)\n",
      "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:310: SyntaxWarning: invalid escape sequence '\\('\n",
      "  elif re.match('(flt)p?( \\(default\\))?$', token):\n",
      "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:314: SyntaxWarning: invalid escape sequence '\\('\n",
      "  elif re.match('(dbl)p?( \\(default\\))?$', token):\n",
      "2025-08-22 17:35:30.395 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-08-22 17:35:30.399 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-08-22 17:35:30.402 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-08-22 17:35:30.837 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-22 17:35:30.840 No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import sys, wikipedia, threading, time, os, vertexai, uvicorn, requests, json, base64, io, av\n",
    "from langchain_google_vertexai import VertexAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from google.colab import auth, userdata\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from pyngrok import ngrok\n",
    "import streamlit as st\n",
    "from google.cloud import texttospeech\n",
    "from google.cloud import speech_v1\n",
    "from pydub import AudioSegment\n",
    "from streamlit_webrtc import webrtc_streamer, WebRtcMode\n",
    "import streamlit.components.v1 as components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E99sKkd2xAJq"
   },
   "source": [
    "## 2. Project configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config_settings",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e4decf03-fa30-4e3f-9f92-d8a35d9cc248"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
     ]
    }
   ],
   "source": [
    "# Project settings\n",
    "# Project parameters\n",
    "location = \"europe-west4\"\n",
    "\n",
    "# Qdrant Configuration\n",
    "collection_name = \"KultuRAG\"\n",
    "qdrant_URL = userdata.get('QDRANT_URL')\n",
    "qdrant_API_key = userdata.get('QDRANT_API_KEY')\n",
    "\n",
    "# ngrok Configuration\n",
    "ngrok_auth_token = userdata.get('NGROK_AUTH_TOKEN')\n",
    "!ngrok config add-authtoken ngrok_auth_token  # Add ngrok token to project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6aGWk7SSxQgS"
   },
   "source": [
    "## 3. Backend\n",
    "\n",
    "This is the core logic of the application, containing all the functions that power the app AI features.\n",
    "\n",
    "**Helper Functions:** This part defines functions to initialize and manage different components.\n",
    "\n",
    "* search_wikipedia_topic: Searches Wikipedia in German for a given topic to provide cultural context for the AI.\n",
    "\n",
    "* initialize_embeddings and initialize_vector_store: Set up the connection to the Qdrant vector database, which stores German sentence examples for the RAG system.\n",
    "\n",
    "* initialize_llm1 and initialize_llm2: Configure two separate instances of the Gemini language model. One is tuned for creative content generation (exercises) and the other is set for more precise responses (feedback).\n",
    "\n",
    "* create_prompt_template: Contains prompt templates that instruct the AI on how to generate reading, writing, listening and speaking exercises, as well as how to provide feedback.\n",
    "\n",
    "* initialize_tts and initialize_stt: Set up Google's Text-to-Speech and Speech-to-Text clients for audio features.\n",
    "\n",
    "**Backend Initialization:** This cell brings all the helper functions together. It initializes the embedding model, connects to the vector store, and prepares the LLMs and prompt templates for use.\n",
    "\n",
    "**FastAPI Application:** This defines the backend server using FastAPI. It sets up several API endpoints that the frontend can call.\n",
    "\n",
    "* /generate_exercises: The main endpoint that takes a topic, language level, and content type from the user. It retrieves relevant data from Wikipedia and the Qdrant vector store. Then, it uses the LLM to generate a complete set of learning materials and exercises.\n",
    "\n",
    "* /feedback: Takes a user's answer to an exercise and generates pedagogical feedback.\n",
    "\n",
    "* /tts and /stt: Handle text-to-speech and speech-to-text conversions for the audio exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "backend_helpers"
   },
   "outputs": [],
   "source": [
    "# Backend helper functions\n",
    "def search_wikipedia_topic(topic, sentences=10):\n",
    "    \"\"\"\n",
    "    Search topic on Wikipedia for cultural and contextual information about it\n",
    "\n",
    "    Args:\n",
    "        topic (str): Topic to search for  // * topic is the topic introduced by the user to formulate the output of the model\n",
    "        sentences (int): Number of sentences in the summary to return\n",
    "\n",
    "    Returns:\n",
    "        str: Wikipedia summary or error message\n",
    "    \"\"\"\n",
    "    try:\n",
    "        wikipedia.set_lang('de')  # Set language to German\n",
    "        search_results = wikipedia.search(topic, results=1)  # Search for the first result of the topic elected by the user\n",
    "        if not search_results:  # If no results are found\n",
    "            return f\"No cultural information found about {topic} on Wikipedia.\"\n",
    "        summary = wikipedia.summary(search_results[0], sentences=sentences)\n",
    "        return summary\n",
    "    except wikipedia.exceptions.DisambiguationError as e:  # If many results are found\n",
    "        try:\n",
    "            return wikipedia.summary(e.options[0], sentences=sentences)  # Choose first result and create summary\n",
    "        except:  # If it fails\n",
    "            return f\"Multiple meanings found for {topic}. Please be more specific\"\n",
    "    except Exception:  # If search fails\n",
    "        return f\"No Wikipedia information found for {topic}\"\n",
    "\n",
    "def initialize_embeddings():\n",
    "    \"\"\"\n",
    "    Initialize embeddings model for vector store\n",
    "\n",
    "    Returns embeddings instance\n",
    "    \"\"\"\n",
    "    # Same model as the model used for indexing\n",
    "    model_name = 'sentence-transformers/all-MiniLM-L6-v2'  # 22.7M parameters, 80MB, open-source\n",
    "    return HuggingFaceEmbeddings(model_name=model_name)\n",
    "\n",
    "def initialize_vector_store(embeddings):\n",
    "    \"\"\"\n",
    "    Initialize Qdrant vector store connection\n",
    "\n",
    "    Args:\n",
    "        embeddings: Embeddings model\n",
    "        collection_name (str): Name of the Qdrant collection\n",
    "        url (str): Qdrant instance URL\n",
    "        api_key (str): Qdrant API key\n",
    "\n",
    "    Returns configured vector store instance or None if connection fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return QdrantVectorStore.from_existing_collection(\n",
    "            embedding=embeddings,  # Embedding model instance\n",
    "            collection_name=collection_name,\n",
    "            url=qdrant_URL,  # Qdrant server URL\n",
    "            api_key=qdrant_API_key,  # Qdrant API key\n",
    "            timeout=300.0  # Give the vector store 5 minutes to find results and not fail\n",
    "        )\n",
    "    except Exception as e:  # If connection fails\n",
    "        print(f\"Could not connect to Qdrant. Proceeding without vector examples. Error: {e}\")\n",
    "        return None  # Return nothing and continue without vector store\n",
    "\n",
    "def initialize_llm1():\n",
    "    \"\"\"\n",
    "    Initialize the language model with the project configuration for exercises\n",
    "\n",
    "    The model will return focused but creative responses\n",
    "\n",
    "    Returns configured language model instance 1\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create the LLM instance\n",
    "        vertexai.init(project=project_ID, location=location)\n",
    "        return VertexAI(\n",
    "            model_name=\"gemini-2.5-flash-lite\",\n",
    "            max_output_tokens=9000,\n",
    "            temperature=0.6,  # Middle temperature for focused but creative responses\n",
    "            top_p=0.8,\n",
    "            verbose=False,  # Disable verbose logging\n",
    "            project=project_ID,\n",
    "            location=location\n",
    "        )\n",
    "    except Exception as e:  # If Vertex AI initialisation fails\n",
    "        print(f\"Error initializing Vertex AI model: {e}\")\n",
    "        print(\"Check credentials and API access\")\n",
    "        return None\n",
    "\n",
    "def initialize_llm2():\n",
    "    \"\"\"\n",
    "    Initialize the language model with the project configuration for feedback\n",
    "\n",
    "    The model will return very focused responses without hallucinations\n",
    "\n",
    "    Returns configured language model instance 2\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create the LLM instance\n",
    "        vertexai.init(project=project_ID, location=location)\n",
    "        return VertexAI(\n",
    "            model_name=\"gemini-2.5-flash-lite\",\n",
    "            max_output_tokens=9000,\n",
    "            temperature=0.1,  # Lower temperature for more focused, less random responses\n",
    "            top_p=0.7,\n",
    "            verbose=False,  # Disable verbose logging\n",
    "            project=project_ID,\n",
    "            location=location\n",
    "        )\n",
    "    except Exception as e:  # If Vertex AI initialisation fails\n",
    "        print(f\"Error initializing Vertex AI model: {e}\")\n",
    "        print(\"Please check credentials and API access\")\n",
    "        return None\n",
    "\n",
    "def validate_inputs(topic, level, content_type):\n",
    "    \"\"\"\n",
    "    Validate user inputs for content generation\n",
    "\n",
    "    Args:\n",
    "        topic (str): Learning topic\n",
    "        level (str): Language level\n",
    "        content_type (str): Type of content to generate\n",
    "\n",
    "    Returns:\n",
    "        tuple: (is_valid, error_message)\n",
    "    \"\"\"\n",
    "    valid_levels = ['A1', 'A2', 'B1', 'B2', 'C1', 'C2']  # List with valid level options\n",
    "    valid_types = ['Kurztext', 'Langtext', 'Geschichte', 'MÃ¤rchen', 'Dialog',\n",
    "                   'Interview', 'Redewendung', 'Rolenspiel', 'Gedicht', 'Drama', 'Liedtext',\n",
    "                   'Online-GesprÃ¤ch', 'Jugendsprache']  # List with valid content type options\n",
    "\n",
    "    if not topic or len(topic.strip()) < 2:  # If topic is not valid or not introduced\n",
    "        return False, \"Please provide a valid topic (at least 2 characters).\"\n",
    "\n",
    "    if level not in valid_levels:  # If level introduced is not valid\n",
    "        return False, f\"Language level must be one of: {', '.join(valid_levels)}\"\n",
    "\n",
    "    if content_type not in valid_types:  # If content type introduced is not valid\n",
    "        return False, f\"Content type must be one of: {', '.join(valid_types)}\"\n",
    "\n",
    "    return True, \"\"  # If every input introduced is correct, return true\n",
    "\n",
    "# Prompts\n",
    "def create_prompt_template():  # Main prompt, for Leseverstehen\n",
    "    \"\"\"\n",
    "    Create a pedagogical prompt template with proper structure and formatting\n",
    "\n",
    "    Returns Prompt template for language learning content\n",
    "    \"\"\"\n",
    "    template = \"\"\"\n",
    "Du bist ein erfahrener Sprachlernexperte und PÃ¤dagoge. Deine Aufgabe ist es, hochwertigen, lernzielorientierten Inhalt zu erstellen, der kulturell authentisch und didaktisch wertvoll ist.\n",
    "Generiere ausschlieÃŸlich den gewÃ¼nschten Inhalt unter BerÃ¼cksichtigung der unten aufgefÃ¼hrten Anweisungen. Verzichte auf Einleitungen, ErklÃ¤rungen oder Kommentare wie â€šKlarâ€˜, â€šHier ist dein Inhaltâ€˜ usw., die nicht Teil der Anweisungen sind.\n",
    "**Behalte ein geordnetes, klares und schÃ¶nes Design bei. Wenn du AufzÃ¤hlungspunkte verwendest, setze jeden AufzÃ¤hlungspunkt in eine neue Zeile. Vom Ausgabeformat dieses Prompts must du die Setzung der ZeilenumbrÃ¼che ('\\n') beachten.**\n",
    "\n",
    "LERNSPEZIFIKATIONEN\n",
    "THEMA: {topic}\n",
    "SPRACHNIVEAU: {level}\n",
    "INHALTSTYP: {content_type}\n",
    "ZIELSPRACHE: Deutsch\n",
    "\n",
    "VERFÃœGBARE RESSOURCEN\n",
    "NATÃœRLICHE SPRACHBEISPIELE AUS DATENBANK: {natural_examples}\n",
    "KULTURELLER KONTEXT AUS WIKIPEDIA: {cultural_context}\n",
    "\n",
    "PÃ„DAGOGISCHE ANWEISUNGEN\n",
    "1. **INHALTSERSTELLUNG:** Erstelle einen authentischen, kulturell relevanten {content_type} Ã¼ber {topic}, der perfekt fÃ¼r das {level}-Niveau geeignet ist.\n",
    "2. **SPRACHNIVEAU-ANPASSUNG:**\n",
    "   - WÃ¤hle Wortschatz und Grammatik entsprechend dem angegebenen Niveau\n",
    "   - Verwende angemessene Satzstrukturen und KomplexitÃ¤t\n",
    "   - BerÃ¼cksichtige typische Lernziele fÃ¼r dieses Niveau\n",
    "3. **KULTURELLE AUTHENTIZITÃ„T:** Integriere die Wikipedia-Informationen geschickt, um kulturelle Tiefe und Kontext zu schaffen.\n",
    "4. **NATÃœRLICHE SPRACHE:** Nutze die Beispiele aus der Datenbank als Inspiration fÃ¼r natÃ¼rlichen, idiomatischen Sprachgebrauch.\n",
    "5. **LERNFÃ–RDERUNG:** Der Inhalt soll interessant, einprÃ¤gsam und lernmotivierend sein.\n",
    "6. **INTERAKTIVE LERNÃœBUNG:**\n",
    "   - Die Ãœbung muss passend und mit Bezug zum generierten Inhalt sein, aber neu, originell und herausfordernd.\n",
    "   - Zeige Keine LÃ¶sungen fÃ¼r die Ãœbung\n",
    "\n",
    "AUSGABEFORMAT (GENAU BEFOLGEN!)\n",
    "**ğŸ¯ {content_type_upper} - SPRACHNIVEAU {level_upper}**\n",
    "\n",
    "[Hier steht dein generierter Lerninhalt - authentisch, kulturell relevant und sprachniveau-gerecht]\\n\\n\n",
    "\n",
    "\n",
    "**ğŸ” SCHWIERIGKEITSEINSCHÃ„TZUNG**\n",
    "\n",
    "ğŸ“Š **Dieser Text entspricht dem Niveau:** {level_upper}\\n\n",
    "ğŸ¯ **Lernziele:** [2-3 spezifische Lernziele, die mit diesem Inhalt erreicht werden]\\n\n",
    "â±ï¸ **GeschÃ¤tzte Bearbeitungszeit:** [X Minuten]\\n\\n\n",
    "\n",
    "\n",
    "**ğŸ“š SCHLÃœSSELVOKABULAR**\n",
    "\n",
    "â€¢ **Wort 1** - [ErklÃ¤rung/Definition + Beispielsatz]\\n\n",
    "â€¢ **Wort 2** - [ErklÃ¤rung/Definition + Beispielsatz]\\n\n",
    "â€¢ **Wort 3** - [ErklÃ¤rung/Definition + Beispielsatz]\\n\n",
    "[... weitere wichtige Vokabeln ...]\\n\\n\n",
    "\n",
    "\n",
    "**ğŸ® LERNÃœBUNG**\n",
    "\n",
    "[Erstelle eine der folgenden Ãœbungstypen:]\n",
    "- LÃ¼ckentext mit Auswahlantworten\n",
    "- Multiple-Choice-Fragen zum TextverstÃ¤ndnis\n",
    "- Richtig/Falsch-Aussagen\n",
    "- Wortschatz-Zuordnungsaufgabe\n",
    "\n",
    "\\n\\n\n",
    "\"\"\"\n",
    "\n",
    "    # Return prompt template with necessary variables\n",
    "    return PromptTemplate(\n",
    "        input_variables=[\"topic\", \"level\", \"level_upper\", \"content_type\", \"content_type_upper\", \"natural_examples\", \"cultural_context\"],\n",
    "        template=template\n",
    "    )\n",
    "\n",
    "def create_writing_exercise_prompt():\n",
    "    \"\"\"\n",
    "    Create prompt template for writing exercise instructions\n",
    "\n",
    "    Returns prompt template for writing exercise\n",
    "    \"\"\"\n",
    "    template = \"\"\"\n",
    "Du bist ein erfahrener Sprachlernexperte und PÃ¤dagoge. Deine Aufgabe ist es, hochwertigen, lernzielorientierten Inhalt zu erstellen, der kulturell authentisch und didaktisch wertvoll ist.\n",
    "Generiere ausschlieÃŸlich den gewÃ¼nschten Inhalt unter BerÃ¼cksichtigung der unten aufgefÃ¼hrten Anweisungen. Verzichte auf Einleitungen, ErklÃ¤rungen oder Kommentare wie â€šKlarâ€˜, â€šHier ist dein Inhaltâ€˜ usw., die nicht Teil der Anweisungen sind.\n",
    "**Behalte ein geordnetes, klares und schÃ¶nes Design bei. Wenn du AufzÃ¤hlungspunkte verwendest, setze jeden AufzÃ¤hlungspunkt in eine neue Zeile. Vom Ausgabeformat dieses Prompts must du die Setzung der ZeilenumbrÃ¼che ('\\n') beachten.**\n",
    "Basierend auf dem generierten Inhalt Ã¼ber {topic} fÃ¼r das Niveau {level}, erstelle eine prÃ¤zise Schreibaufgabe.\n",
    "\n",
    "GENERIERTER HAUPTINHALT ZUR REFERENZ:\n",
    "{main_content}\n",
    "\n",
    "AUFGABE: Erstelle klare Anweisungen fÃ¼r eine SchreibÃ¼bung, die zum Hauptinhalt passt. Zeige Keine LÃ¶sungen fÃ¼r die Ãœbung.\n",
    "\n",
    "FORMAT (GENAU BEFOLGEN!):\n",
    "**ğŸ“ SCHREIBAUFGABE**\n",
    "\n",
    "**Thema:** [Spezifisches Schreibthema basierend auf dem Hauptinhalt]\\n\\n\n",
    "\n",
    "**Anweisungen:**\\n\n",
    "â€¢ [Klare Aufgabenstellung]\\n\n",
    "â€¢ [LÃ¤nge: X WÃ¶rter/SÃ¤tze]\\n\n",
    "â€¢ [Zu verwendende Grammatikstrukturen]\\n\n",
    "â€¢ [Erforderlicher Wortschatz]\\n\\n\n",
    "\n",
    "**Bewertungskriterien:**\\n\n",
    "â€¢ Grammatik und Rechtschreibung\\n\n",
    "â€¢ Verwendung des thematischen Vokabulars\\n\n",
    "â€¢ Struktur und KohÃ¤renz\\n\n",
    "â€¢ KreativitÃ¤t und OriginalitÃ¤t\\n\\n\n",
    "\"\"\"\n",
    "\n",
    "    # Return prompt template with necessary variables\n",
    "    return PromptTemplate(\n",
    "        input_variables=[\"topic\", \"level\", \"main_content\"],\n",
    "        template=template\n",
    "    )\n",
    "\n",
    "def create_audio_comprehension_prompt():\n",
    "    \"\"\"\n",
    "    Create prompt template for audio comprehension exercise\n",
    "\n",
    "    Returns prompt template for audio exercise\n",
    "    \"\"\"\n",
    "    template = \"\"\"\n",
    "Du bist ein erfahrener Sprachlernexperte und PÃ¤dagoge. Deine Aufgabe ist es, hochwertigen, lernzielorientierten Inhalt zu erstellen, der kulturell authentisch und didaktisch wertvoll ist.\n",
    "Generiere ausschlieÃŸlich den gewÃ¼nschten Inhalt unter BerÃ¼cksichtigung der unten aufgefÃ¼hrten Anweisungen. Verzichte auf Einleitungen, ErklÃ¤rungen oder Kommentare wie â€šKlarâ€˜, â€šHier ist dein Inhaltâ€˜ usw., die nicht Teil der Anweisungen sind.\n",
    "**Behalte ein geordnetes, klares und schÃ¶nes Design bei. Wenn du AufzÃ¤hlungspunkte verwendest, setze jeden AufzÃ¤hlungspunkt in eine neue Zeile. Vom Ausgabeformat dieses Prompts must du die Setzung der ZeilenumbrÃ¼che ('\\n') beachten.**\n",
    "Erstelle einen HÃ¶rtext und Ãœbungen fÃ¼r {topic} auf Niveau {level}.\n",
    "\n",
    "BEZUG ZUM HAUPTINHALT:\n",
    "{main_content}\n",
    "\n",
    "ERSTELLE:\n",
    "1. Einen Text zum Vorlesen (150-300 WÃ¶rter je nach Niveau). Generiere nur den reinen Text, keine Anweisungen zwischen Klammern bzgl. Stimmen, Musik usw. **Der Text muss neu sein, nicht gleich oder Ã¤hnlich wie der Hauptinhalt sein.** Beim HÃ¶rtext, benutze keine Emojis.\n",
    "2. VerstÃ¤ndnisfragen zum HÃ¶rtext. Zeige keine LÃ¶sungen fÃ¼r die Ãœbung.\n",
    "\n",
    "FORMAT (GENAU BEFOLGEN!):\n",
    "[Hier den vollstÃ¤ndigen HÃ¶rtext - klar strukturiert, niveau-gerecht]\n",
    "\n",
    "\\n\\n**ğŸ“‹ VERSTÃ„NDNISFRAGEN**\\n\\n\n",
    "\n",
    "\\n1. [Frage 1]\\n\n",
    "   a) [Option A]\\n\n",
    "   b) [Option B]\\n\n",
    "   c) [Option C]\\n\\n\n",
    "\n",
    "2. [Frage 2]\\n\n",
    "   a) [Option A]\\n\n",
    "   b) [Option B]\\n\n",
    "   c) [Option C]\\n\\n\n",
    "\n",
    "3. [Frage 3 - Richtig/Falsch]\\n\\n\n",
    "\"\"\"\n",
    "\n",
    "    # Return prompt template with necessary variables\n",
    "    return PromptTemplate(\n",
    "        input_variables=[\"topic\", \"level\", \"main_content\"],\n",
    "        template=template\n",
    "    )\n",
    "\n",
    "def create_speaking_exercise_prompt():\n",
    "    \"\"\"\n",
    "    Create prompt template for speaking exercise instructions\n",
    "\n",
    "    Returns prompt template for speaking exercise\n",
    "    \"\"\"\n",
    "    template = \"\"\"\n",
    "Du bist ein erfahrener Sprachlernexperte und PÃ¤dagoge. Deine Aufgabe ist es, hochwertigen, lernzielorientierten Inhalt zu erstellen, der kulturell authentisch und didaktisch wertvoll ist.\n",
    "Generiere ausschlieÃŸlich den gewÃ¼nschten Inhalt unter BerÃ¼cksichtigung der unten aufgefÃ¼hrten Anweisungen. Verzichte auf Einleitungen, ErklÃ¤rungen oder Kommentare wie â€šKlarâ€˜, â€šHier ist dein Inhaltâ€˜ usw., die nicht Teil der Anweisungen sind.\n",
    "**Behalte ein geordnetes, klares und schÃ¶nes Design bei. Wenn du AufzÃ¤hlungspunkte verwendest, setze jeden AufzÃ¤hlungspunkt in eine neue Zeile (wenn du Unterteilungen innerhalb eines AufzÃ¤hlungspunktes verwendest (mit diesem Symbol: - ), musst du jede Unterteilung ebenfalls in eine neue Zeile setzen.). Vom Ausgabeformat dieses Prompts must du die Setzung der ZeilenumbrÃ¼che ('\\n') beachten.**\n",
    "Erstelle eine Sprechaufgabe fÃ¼r {topic} auf Niveau {level}, die zum Hauptinhalt passt.\n",
    "\n",
    "HAUPTINHALT:\n",
    "{main_content}\n",
    "\n",
    "AUFGABE: Erstelle klare Anweisungen und Tipps fÃ¼r eine Sprechaufgabe, die zum Hauptinhalt passt. Zeige Keine LÃ¶sungen fÃ¼r die Ãœbung.\n",
    "\n",
    "FORMAT (GENAU BEFOLGEN!):\n",
    "**ğŸ¤ SPRECHAUFGABE**\\n\n",
    "\n",
    "**Aufgabe:** [Klares Sprechthema]\\n\\n\n",
    "\n",
    "**Anweisungen:**\\n\n",
    "â€¢ **Sprechdauer:** [X Minuten]\\n\n",
    "â€¢ **Struktur:** [Einleitung, Hauptteil, Schluss]\\n\n",
    "â€¢ **Zu verwendende Redemittel:** [Liste wichtiger Phrasen]\\n\n",
    "â€¢ **Schwerpunkte:** [Grammatik/Vokabular-Fokus]\\n\\n\n",
    "\n",
    "**Tipps:**\\n\n",
    "â€¢ [Tipp 1 fÃ¼r gute Aussprache]\\n\n",
    "â€¢ [Tipp 2 fÃ¼r Struktur]\\n\n",
    "â€¢ [Tipp 3 fÃ¼r FlÃ¼ssigkeit]\\n\\n\n",
    "\"\"\"\n",
    "\n",
    "    # Return prompt template with necessary variables\n",
    "    return PromptTemplate(\n",
    "        input_variables=[\"topic\", \"level\", \"main_content\"],\n",
    "        template=template\n",
    "    )\n",
    "\n",
    "def create_feedback_prompt():\n",
    "    \"\"\"\n",
    "    Create prompt template for exercise feedback\n",
    "\n",
    "    Returns prompt template for providing feedback\n",
    "    \"\"\"\n",
    "    template = \"\"\"\n",
    "Du bist ein erfahrener Sprachlernexperte und PÃ¤dagoge. Deine Aufgabe ist es, hochwertigen, lernzielorientierten Inhalt zu erstellen, der kulturell authentisch und didaktisch wertvoll ist.\n",
    "Generiere ausschlieÃŸlich den gewÃ¼nschten Inhalt unter BerÃ¼cksichtigung der unten aufgefÃ¼hrten Anweisungen. Verzichte auf Einleitungen, ErklÃ¤rungen oder Kommentare wie â€šKlarâ€˜, â€šHier ist dein Inhaltâ€˜ usw., die nicht Teil der Anweisungen sind.\n",
    "**Behalte ein geordnetes, klares und schÃ¶nes Design bei. Wenn du AufzÃ¤hlungspunkte verwendest, setze jeden AufzÃ¤hlungspunkt in eine neue Zeile. Vom Ausgabeformat dieses Prompts must du die Setzung der ZeilenumbrÃ¼che ('\\n') beachten.**\n",
    "Bewerte die folgende {exercise_type} eines {level}-Lerners zum Thema {topic}. **Bewerte nur die unterstehende ANTWORT DES LERNERS.** Achte darauf, dass der Lerner bei LÃ¼ckentextÃ¼bungen oder Multiple-Choice-Fragen (unter anderem) ggf. nicht die ganze SÃ¤tze aufgrund von Zeitsparnis schreiben wird.\n",
    "\n",
    "AUFGABENSTELLUNG:\n",
    "{task_instructions}\n",
    "\n",
    "______________________________________________\n",
    "ANTWORT DES LERNERS (**dies ist das Einzige, was vom Nutzer erstellt wurde und von dir bewertet werden muss.**):\n",
    "{user_response}\n",
    "______________________________________________\n",
    "\n",
    "Gib konstruktives, ermutigendes Feedback. Richte das Feedback direkt an den Lernenden. Halte das Feedback realistisch, professionell und an die Ãœbung angepasst; akzeptiere keine unvollstÃ¤ndigen oder schlechten Ãœbungen.\n",
    "\n",
    "FORMAT (GENAU BEFOLGEN!):\n",
    "âœ… FEEDBACK\n",
    "\n",
    "**Bewertung:** [Note/Punkte]\\n\\n\n",
    "\n",
    "**StÃ¤rken:**\\n\n",
    "â€¢ [Positive Aspekte]\\n\n",
    "â€¢ [Was gut gemacht wurde]\\n\\n\n",
    "\n",
    "**VerbesserungsvorschlÃ¤ge:**\\n\n",
    "â€¢ [Konstruktive Kritik]\\n\n",
    "â€¢ [Konkrete Verbesserungen]\\n\\n\n",
    "\n",
    "**Korrekturen:**\\n\n",
    "â€¢ [Fehler â†’ Korrektur]\\n\n",
    "â€¢ [Fehler â†’ Korrektur]\\n\\n\n",
    "\n",
    "**NÃ¤chste Schritte:**\\n\n",
    "â€¢ [Empfehlung fÃ¼r weiteres Lernen]\n",
    "\"\"\"\n",
    "\n",
    "    # Return prompt template with necessary variables\n",
    "    return PromptTemplate(\n",
    "        input_variables=[\"exercise_type\", \"level\", \"topic\", \"task_instructions\", \"user_response\"],\n",
    "        template=template\n",
    "    )\n",
    "\n",
    "def initialize_tts():\n",
    "    \"\"\"\n",
    "    Initialize Google Text-to-Speech client\n",
    "\n",
    "    Returns TTS client instance\n",
    "    \"\"\"\n",
    "    try:  # Start and return TTS client\n",
    "        client = texttospeech.TextToSpeechClient()\n",
    "        return client\n",
    "    except Exception as e:  # If it fails\n",
    "        print(f\"TTS initialization failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def initialize_stt():\n",
    "    \"\"\"\n",
    "    Initialize Google Speech-to-Text client\n",
    "\n",
    "    Returns STT client instance\n",
    "    \"\"\"\n",
    "    try:  # Start STT client\n",
    "        client = speech_v1.SpeechClient()\n",
    "        return client\n",
    "    except Exception as e:  # If it fails\n",
    "        print(f\"STT initialization failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def text_to_speech(text, tts_client):\n",
    "    \"\"\"\n",
    "    Convert text to speech using Google TTS\n",
    "\n",
    "    Args:\n",
    "        text (str): Text to convert\n",
    "        tts_client: Google TTS client\n",
    "\n",
    "    Returns:\n",
    "        bytes: Audio content in MP3 format\n",
    "    \"\"\"\n",
    "    if not tts_client:  # If no TTS client available\n",
    "        return None\n",
    "\n",
    "    try:  # If TTS client available\n",
    "        synthesis_input = texttospeech.SynthesisInput(text=text)  # Select text to be read\n",
    "\n",
    "        # Select voice\n",
    "        voice = texttospeech.VoiceSelectionParams(\n",
    "            language_code=\"de-DE\",\n",
    "            ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL\n",
    "        )\n",
    "\n",
    "        # Select encoding for the generated audio\n",
    "        audio_config = texttospeech.AudioConfig(\n",
    "            audio_encoding=texttospeech.AudioEncoding.MP3  # .mp3\n",
    "        )\n",
    "\n",
    "        # Generate audio\n",
    "        response = tts_client.synthesize_speech(\n",
    "            input=synthesis_input,\n",
    "            voice=voice,\n",
    "            audio_config=audio_config\n",
    "        )\n",
    "\n",
    "        return response.audio_content\n",
    "\n",
    "    except Exception as e:  # If audio generation fails\n",
    "        print(f\"TTS conversion failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def speech_to_text(audio_content, stt_client, sample_rate_hertz, topic: str):\n",
    "    \"\"\"\n",
    "    Convert speech to text using Google STT with an advanced configuration\n",
    "    \"\"\"\n",
    "    if not stt_client:  # If no STT client is available\n",
    "        return \"\"\n",
    "\n",
    "    try:  # If STT client is available\n",
    "        audio = speech_v1.RecognitionAudio(content=audio_content)  # Get audio\n",
    "\n",
    "        adaptation_client = speech_v1.AdaptationClient()\n",
    "        phrase_set = speech_v1.PhraseSet()\n",
    "\n",
    "        # The topic provides context to the model\n",
    "        phrase_set.phrases = [speech_v1.PhraseSet.Phrase(value=topic)]\n",
    "        phrase_set.boost = 20.0\n",
    "\n",
    "        adaptation = speech_v1.SpeechAdaptation(phrase_sets=[phrase_set])\n",
    "\n",
    "        # Configuration or voice recognition\n",
    "        config = speech_v1.RecognitionConfig(\n",
    "            encoding=speech_v1.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "            sample_rate_hertz=sample_rate_hertz,\n",
    "            language_code=\"de-DE\",\n",
    "            model=\"latest_long\",\n",
    "            enable_automatic_punctuation=True,\n",
    "            enable_word_time_offsets=False,\n",
    "            adaptation=adaptation  # Apply the topic hint\n",
    "        )\n",
    "\n",
    "        response = stt_client.recognize(config=config, audio=audio)  # Response from the recognition system\n",
    "        transcript = \"\".join(result.alternatives[0].transcript for result in response.results)  # Transcript generation joining all results\n",
    "\n",
    "        if not transcript.strip():  # If no transcript could be created\n",
    "            return \"NO_SPEECH_DETECTED\"\n",
    "\n",
    "        return transcript.strip()  # If transcript was created, return it\n",
    "\n",
    "    except Exception as e:  # If something failed\n",
    "        print(f\"STT conversion failed: {e}\")\n",
    "        return f\"STT_ERROR: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493,
     "referenced_widgets": [
      "9e068fec13ae47f2be598ff51ba4d08f",
      "da4b2a78674a474a952d753cc5d01166",
      "14329f25ec4d4bf8a48d7f47a42d3ba6",
      "c02d73079e864b25b2d2d40771698462",
      "b0b9ad7cfd6e412083a70848d7d302f4",
      "7bed85727e2b48ceb6a76c9d0fc293cb",
      "b9095dc2bde04606b4aacf12ccc65eb1",
      "4f9e24dd404443f48c37389f915a8596",
      "fc68e9be4ec847a6a8466f29741a2b24",
      "c8014232d58847b9b5bcda8161b830db",
      "3ef0db4cca7a45c4aa726021c2f86299",
      "7bf4f3fe9c1e434199a5f9c2f5519c61",
      "789f3196c5b7482b9cb0493aa8f2bd53",
      "b2bea2b0116a40fb82a7a93142161195",
      "d9acc595c99845ac80b29bb921b4429d",
      "a3dd9c48d1194c1aa42a4644a4395d2c",
      "683b52aad6cf44ea80be5b5e19fb0e4a",
      "cec9133b7b1b4b74a6460b6bba6382ab",
      "1ead994cd57d45ddafc49e3998ec22d0",
      "fb9032b826774111976089f21ed0a2dc",
      "116a1e23ec9e467b80f37870023338a2",
      "adead7a321474e888706964a624b1e17",
      "b7d74d65ba2f4f7f9c53fb29fd166fcf",
      "e6ccc876df754e11a9fdb045e3cbb2a6",
      "8eb12d3aaa464cd38f2b667b9b237402",
      "40a4cb60d68b4601a8e512a6f87a9094",
      "0d2c8b9616e04c808bca3cab5b922055",
      "5e3325acdcb5400da75e88e4f2b15353",
      "7f16df5cf1ae48cd81061aec654e4d31",
      "02a8ce221a0e48aba6193bf7ab8c2c11",
      "f68c8ffcd22c48fea0a634e3233e59ca",
      "788721533a5f431e83cfffa78e77cdc4",
      "0b82f9e9a56147feaec33b9ba33182f3",
      "0dacd0dcaef54462a7c832ee8550a983",
      "a7a0e591e2714501a994ab7fa6c6897f",
      "534cad5a19a44b5fb4ed210701749156",
      "a6f4f9eda00045af9e69c8729197aa9a",
      "18ae6fd6ec534d12aed8bc6ec0fec1ea",
      "809a77ab67624a45be3f3ba2fb797d14",
      "593227d9b5b843458b809fad465623fd",
      "23d2c0ecf2d0422ab781670c21813752",
      "62f6a3f4b007457cbb2eea8c1773aa0a",
      "7bec3c0db31b4a3e82c6244b73884099",
      "2870946f1e994a7984d392b714df4f8a",
      "ff8ff4cadbf9408dac6ad4fec745d52b",
      "1937dd48ffb24a4eb8eccbf42edbea47",
      "ec34f0f16d7a4cc0a53ab7d1f7848dc9",
      "931fbfe328cf468d810f876b840ccb3d",
      "41ef582db00c4af6a05b0f3782c5d41c",
      "ad19d6b10df5442da10102961722bfc3",
      "12f08938dc084488951fb2f0304be58d",
      "5e4793f06b744d74a0ec9aa33ef0cdbf",
      "02dd19d1d4fc4d5287c0ec70c1dcdb2f",
      "4492fe7b87a044baa2306abb9c89bbc6",
      "27ec2a314a954f2e8169e6d3f7518ca4",
      "a1a1522c8c474e5092c8c5f15599abb7",
      "49127e9c8c3045ee8399b5a12796d505",
      "4cddbc1d73194b5688ae249f39976640",
      "c2bf53c9d4324286bd039f583a8c0cad",
      "675e778232684a73940f2513bf227fff",
      "196c23d3c1ee42c7b62b884f8b3aa57c",
      "a32bc914aba241b794ee72b15b410013",
      "10bad205738e4552a6c8f2812e040078",
      "b2a278e6f3a54bbd8e9406be5d8af510",
      "ed5a46e6cde54ccdaf29d77c205cf0f9",
      "a373bf7b9e424a42ab41760989ebae82",
      "a7cd9c3ea4c24bb8af5549e8296af074",
      "92abd73d5c574e778c857869853d3925",
      "f6c0d5bebc0f471089822612c05f8f4b",
      "ac4f50f12aa9481bb26182045f49ea7f",
      "52130934b7fd47f2ac5c8fd7ec21f30c",
      "fcd0819c5fa74921906094aeef09b6c2",
      "393abbb513734f56aa4ef8b36a7d09eb",
      "9543fc8d370c4a789c09fab45ae36a2f",
      "87f72417e47749eda03fa628f76727c3",
      "5c0d3efe9df547c7bdd812482ce670c3",
      "0cc67801a4234c7a9b4113db7c25e3c1",
      "85cc692f1fd946a79bb16a4f75a8614b",
      "77718f778cc14dcdad5fd21b986e7e6b",
      "68e977ceff4943dbaaaf7659893c1a25",
      "a69b3e278dd94d3780f625d7b63a7dc8",
      "ed6ebaa87df044458f4aacd2624e9e99",
      "9d8b97965c85470394af89633c11a8fb",
      "f92297830b2b49cd95a6161d92275364",
      "aa0e41a183c64ace95b9089159d9a71d",
      "d554cd84320e4cff82a9539602d27de7",
      "15bc1a02c35e42d3801142d83127721a",
      "8e76abd395ea47199bbc70d113373244",
      "f3b75f8b786344bbb044c85c5c11ae2e",
      "79566866dbeb47b59493d6ab9cd28b1d",
      "529ba8189d494f389e31561e2a884202",
      "314b59b25ecc4accbed269a455aaf559",
      "c0f2ce0a031a491e89b007172c737c49",
      "7b9ffe06fda64970bef855bff5749764",
      "2fd52de0b87c41ebb907d32a8bb971fb",
      "9d95731f199341bb8730bb484af8d5b2",
      "c62a581edaed4053a32968c110f4e68e",
      "2a93401b0e144ef3af14554795ac26f5",
      "73e31d694ec24c5a9020f8e55fcb24ee",
      "d96f1f35801a46f58477a7b46783d182",
      "478dc4651e644e5eb07d7bbfbb5aac7c",
      "7880f781a13c492094acc86428fe32d0",
      "fe5e88a1d0d24a629203fbfa52e76015",
      "9d6c162c80484b6a9a4dfb00224a30cb",
      "bfcf383b832749cea74b40b473972da3",
      "fb5c1906b81345c99c9c5e12cbcbcba2",
      "3671a95f91a640e280813c662a71128f",
      "1f7128f8613f4f8c8bccdd1cfda6e2b7",
      "6dea4b427fd74e01ab6887f50f0fe81f",
      "5f6f9f42be434ba59408e39cd90ab349",
      "d7a3c81abc324d21a484d69b645749a1",
      "4f132a762c8c492393bd34c68b2805f1",
      "e004d93443b041e7b7fe57a52910c8cd",
      "53bb4ae8169e4f3f93242e7271d730e3",
      "2fb2f47c4f1949fe90f50ff639c5067b",
      "4cf02627ba9643e596dd493c9306d106",
      "053b1c16ec86447ea3c7fee60424b63d",
      "2f3c24df6d134adc91dff100fa9fad9d",
      "b049dca244af458d9e9d25a65603312d",
      "1d3adde0435d4290afdc9775c664619d",
      "2cf1914a90c845948d772e18a90c45d5"
     ]
    },
    "id": "init_backend",
    "outputId": "ea1b1c1b-e693-4fed-f069-8ba42489afa4"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e068fec13ae47f2be598ff51ba4d08f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7bf4f3fe9c1e434199a5f9c2f5519c61"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b7d74d65ba2f4f7f9c53fb29fd166fcf"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0dacd0dcaef54462a7c832ee8550a983"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff8ff4cadbf9408dac6ad4fec745d52b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1a1522c8c474e5092c8c5f15599abb7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a7cd9c3ea4c24bb8af5549e8296af074"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85cc692f1fd946a79bb16a4f75a8614b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3b75f8b786344bbb044c85c5c11ae2e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d96f1f35801a46f58477a7b46783d182"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d7a3c81abc324d21a484d69b645749a1"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Initialize backend components\n",
    "\n",
    "embeddings = initialize_embeddings()  # Initialize embeddings\n",
    "vector_store = initialize_vector_store(embeddings)  # Connect to vector store\n",
    "llm1 = initialize_llm1()  # Start LLM 1 for exercises\n",
    "llm2 = initialize_llm2()  # Start LLM 2 for feedback\n",
    "\n",
    "if vector_store:  # If vector store connection is working\n",
    "    retriever = vector_store.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 3})  # Set retriever, return top 3 relevant documents\n",
    "else:  # If it is not working\n",
    "    retriever = None  # Continue app without retriever (without RAG)\n",
    "    print(\"Vector store connection failed, continuing without retrieval\")\n",
    "\n",
    "if llm1:  # If LLM 1 is working\n",
    "    # Initialize\n",
    "    prompt = create_prompt_template()  # Create main prompt template\n",
    "    writing_prompt = create_writing_exercise_prompt()  # Create writing prompt template\n",
    "    audio_prompt = create_audio_comprehension_prompt()  # Create audio prompt template\n",
    "    speaking_prompt = create_speaking_exercise_prompt()  # Create speaking prompt template\n",
    "else:  # If it is not working\n",
    "    raise RuntimeError(\"LLM initialization failed. Cannot continue\")  # Stop execution; app cannot be executed without LLM\n",
    "\n",
    "if llm2:  # If LLM 2 is working\n",
    "    # Initialize\n",
    "    feedback_prompt = create_feedback_prompt()  # Create feedback prompt template\n",
    "else:  # If it is not working\n",
    "    raise RuntimeError(\"LLM initialization failed. Cannot continue\")  # Stop execution; app cannot be executed without LLM\n",
    "\n",
    "# Initialize TTS and STT clients\n",
    "tts_client = initialize_tts()  # text-to-speech\n",
    "stt_client = initialize_stt()  # Speech-to-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "define_fastapi"
   },
   "outputs": [],
   "source": [
    "# Define the FastAPI backend application\n",
    "\n",
    "# FastAPI initialization with title and description of the project\n",
    "app_backend = FastAPI(title=\"KultuRAG API\", description=\"Cultural AI Language Learning Assistant with RAG\")\n",
    "\n",
    "# Define the data structures (Pydantic models) for incoming API requests using Pydantic\n",
    "class ContentRequest(BaseModel):\n",
    "    \"\"\"Defines the expected JSON structure for the main content generation request\"\"\"\n",
    "    thema: str\n",
    "    sprachniveau: str\n",
    "    inhaltstyp: str\n",
    "\n",
    "class FeedbackRequest(BaseModel):\n",
    "    \"\"\"Request structure for exercise feedback\"\"\"\n",
    "    exercise_type: str\n",
    "    level: str\n",
    "    topic: str\n",
    "    task_instructions: str\n",
    "    user_response: str\n",
    "\n",
    "class TTSRequest(BaseModel):\n",
    "    \"\"\"Request structure for text-to-speech\"\"\"\n",
    "    text: str\n",
    "\n",
    "class STTRequest(BaseModel):\n",
    "    \"\"\"Request structure for speech-to-text\"\"\"\n",
    "    audio_data: str\n",
    "    sample_rate: int\n",
    "    topic: str\n",
    "\n",
    "# API endpoints\n",
    "@app_backend.get(\"/\")\n",
    "def root():\n",
    "    \"\"\"\n",
    "    Root endpoint for basic connectivity checks\n",
    "\n",
    "    Provides a simple, welcoming message to confirm that the API server is running and accessible\n",
    "    \"\"\"\n",
    "    return {\"message\": \"KultuRAG Backend is running!\", \"status\": \"healthy\"}\n",
    "\n",
    "@app_backend.get(\"/health\")\n",
    "def health_check():\n",
    "    \"\"\"\n",
    "    Health check endpoint for monitoring the status of the services\n",
    "\n",
    "    This endpoint verifies the availability of components like the LLM and the vector store\n",
    "\n",
    "    Returns:\n",
    "        dict: A JSON object indicating the overall status and the status of individual components\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"status\": \"healthy\",\n",
    "        \"llm_available\": llm is not None,\n",
    "        \"vector_store_available\": vector_store is not None,\n",
    "    }\n",
    "\n",
    "@app_backend.post(\"/generate\")\n",
    "async def generate_content_exercises(request: ContentRequest):\n",
    "    \"\"\"\n",
    "\n",
    "    Main endpoint for generating the main learning content\n",
    "\n",
    "    This function manages the entire RAG process based on the user's request. It validates input, retrieves contextual data, and invokes the LLM to generate the final content\n",
    "\n",
    "    Args:\n",
    "        request (ContentRequest): A Pydantic model containing the topic, language level and content type\n",
    "\n",
    "    Raises:\n",
    "        HTTPException: 400 for invalid user input\n",
    "\n",
    "        HTTPException: 500 for internal errors during RAG or LLM processing\n",
    "\n",
    "    Returns:\n",
    "        dict: A JSON object containing the generated learning content\n",
    "    \"\"\"\n",
    "\n",
    "    # Input validation\n",
    "    is_valid, error_msg = validate_inputs(request.thema, request.sprachniveau, request.inhaltstyp)\n",
    "    if not is_valid:  # If not all elements are valid\n",
    "        raise HTTPException(status_code=400, detail=error_msg)  # Raise error\n",
    "\n",
    "    print(f\"Received request: {request.thema} | {request.sprachniveau} | {request.inhaltstyp}\")\n",
    "\n",
    "    # Retrieve examples from vector store - RAG\n",
    "    # Get examples from the Qdrant vector store\n",
    "    natural_examples = \"â€¢ Keine spezifischen Beispiele verfÃ¼gbar.\"  # Standard example before doing the search in the vector database\n",
    "    if retriever:  # If retriever is working\n",
    "        try:\n",
    "            docs = retriever.invoke(request.thema)  # Retrieve examples of the desired topic\n",
    "            if docs:  # If some examples were found\n",
    "                natural_examples = \"\\n\".join([f\"â€¢ {doc.page_content}\" for doc in docs])  # substitute standard example for new examples\n",
    "        except Exception as e:  # If search failed\n",
    "            print(f\"Vector store query failed: {e}\")\n",
    "\n",
    "    # Get cultural context from Wikipedia\n",
    "    cultural_context = search_wikipedia_topic(request.thema)\n",
    "\n",
    "    # Generate content with LLM\n",
    "    try:\n",
    "        # Format prompt with variables\n",
    "        formatted_prompt = prompt.format(\n",
    "            topic=request.thema,\n",
    "            level=request.sprachniveau.lower(),\n",
    "            level_upper=request.sprachniveau.upper(),\n",
    "            content_type=request.inhaltstyp,\n",
    "            content_type_upper=request.inhaltstyp.upper(),\n",
    "            natural_examples=natural_examples,\n",
    "            cultural_context=cultural_context\n",
    "        )\n",
    "\n",
    "        # Generate content with the LLM 1\n",
    "        response = llm1.invoke(formatted_prompt)\n",
    "\n",
    "        return {\"content\": response}\n",
    "\n",
    "    except Exception as e:  # If generation fails\n",
    "        print(f\"LLM generation failed: {e}\")\n",
    "        raise HTTPException(status_code=500, detail=f\"Error generating content: {e}\")  # Raise exception\n",
    "\n",
    "@app_backend.post(\"/generate\")\n",
    "async def generate_content_feedback(request: ContentRequest):\n",
    "    \"\"\"\n",
    "    Main endpoint for generating the main learning content\n",
    "\n",
    "    This function manages the RAG process based on the user's request. It validates input, retrieves contextual data, and invokes the LLM to generate the final content\n",
    "\n",
    "    Args:\n",
    "        request (ContentRequest): A Pydantic model containing the topic, language level and content type\n",
    "\n",
    "    Raises:\n",
    "        HTTPException: 400 for invalid user input\n",
    "\n",
    "        HTTPException: 500 for internal errors during RAG or LLM processing\n",
    "\n",
    "    Returns:\n",
    "        dict: A JSON object containing the generated learning content\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    is_valid, error_msg = validate_inputs(request.thema, request.sprachniveau, request.inhaltstyp)\n",
    "    if not is_valid:  # If not all elements are valid\n",
    "        raise HTTPException(status_code=400, detail=error_msg)  # Raise error\n",
    "\n",
    "    print(f\"Received request: {request.thema} | {request.sprachniveau} | {request.inhaltstyp}\")\n",
    "\n",
    "    # Retrieve examples from vector store - RAG\n",
    "    # Get examples from the Qdrant vector store\n",
    "    natural_examples = \"Keine spezifischen Beispiele verfÃ¼gbar\"  # Standard example before doing the search in the vector database\n",
    "    if retriever:  # If retriever is working\n",
    "        try:\n",
    "            docs = retriever.invoke(request.thema)  # Retrieve examples of the desired topic\n",
    "            if docs:  # If some documents were found\n",
    "                natural_examples = \"\\n\".join([f\"â€¢ {doc.page_content}\" for doc in docs])  # substitute standard example for new examples\n",
    "        except Exception as e:  # If search failed\n",
    "            print(f\"Vector store query failed: {e}\")\n",
    "\n",
    "    # Get cultural context from Wikipedia\n",
    "    cultural_context = search_wikipedia_topic(request.thema)\n",
    "\n",
    "    # Generate content with LLM\n",
    "    try:\n",
    "        # Format prompt with variables\n",
    "        formatted_prompt = prompt.format(\n",
    "            topic=request.thema,\n",
    "            level=request.sprachniveau.lower(),\n",
    "            level_upper=request.sprachniveau.upper(),\n",
    "            content_type=request.inhaltstyp,\n",
    "            content_type_upper=request.inhaltstyp.upper(),\n",
    "            natural_examples=natural_examples,\n",
    "            cultural_context=cultural_context\n",
    "        )\n",
    "\n",
    "        # Generate content with the LLM 2\n",
    "        response = llm2.invoke(formatted_prompt)\n",
    "\n",
    "        return {\"content\": response}\n",
    "\n",
    "    except Exception as e:  # If generation fails\n",
    "        print(f\"LLM generation failed: {e}\")\n",
    "        raise HTTPException(status_code=500, detail=f\"Error generating content: {e}\")  # Raise exception\n",
    "\n",
    "\n",
    "@app_backend.post(\"/generate_exercises\")\n",
    "async def generate_all_exercises(request: ContentRequest):\n",
    "    \"\"\"\n",
    "    Generate all exercise types based on main content\n",
    "\n",
    "    Returns all exercises together after generation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # First generate main content\n",
    "        main_content_response = await generate_content_exercises(request)  # Wait until content is generated\n",
    "        main_content = main_content_response[\"content\"]\n",
    "\n",
    "        # Generate writing exercise\n",
    "        writing_exercise = llm1.invoke(\n",
    "            writing_prompt.format(\n",
    "                topic=request.thema,\n",
    "                level=request.sprachniveau,\n",
    "                main_content=main_content\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Generate audio comprehension exercise\n",
    "        audio_exercise = llm1.invoke(\n",
    "            audio_prompt.format(\n",
    "                topic=request.thema,\n",
    "                level=request.sprachniveau,\n",
    "                main_content=main_content\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Generate speaking exercise\n",
    "        speaking_exercise = llm1.invoke(\n",
    "            speaking_prompt.format(\n",
    "                topic=request.thema,\n",
    "                level=request.sprachniveau,\n",
    "                main_content=main_content\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Return all generated content\n",
    "        return {\n",
    "            \"main_content\": main_content,\n",
    "            \"writing_exercise\": writing_exercise,\n",
    "            \"audio_exercise\": audio_exercise,\n",
    "            \"speaking_exercise\": speaking_exercise\n",
    "        }\n",
    "\n",
    "    except Exception as e:  # If generation failed\n",
    "        raise HTTPException(status_code=500, detail=f\"Exercise generation failed: {e}\")\n",
    "\n",
    "@app_backend.post(\"/feedback\")\n",
    "async def provide_feedback(request: FeedbackRequest):\n",
    "    \"\"\"\n",
    "    Provide feedback for user's exercise response\n",
    "    \"\"\"\n",
    "    try:\n",
    "        feedback = llm2.invoke(\n",
    "            feedback_prompt.format(\n",
    "                exercise_type=request.exercise_type,\n",
    "                level=request.level,\n",
    "                topic=request.topic,\n",
    "                task_instructions=request.task_instructions,\n",
    "                user_response=request.user_response\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return {\"feedback\": feedback}\n",
    "\n",
    "    except Exception as e:  # If generation failed\n",
    "        raise HTTPException(status_code=500, detail=f\"Feedback generation failed: {e}\")\n",
    "\n",
    "@app_backend.post(\"/tts\")\n",
    "async def text_to_speech_endpoint(request: TTSRequest):\n",
    "    \"\"\"\n",
    "    Convert text to speech\n",
    "    \"\"\"\n",
    "    try:\n",
    "        audio_content = text_to_speech(request.text, tts_client)  # Convertion\n",
    "        if audio_content:  # If conversion was successful\n",
    "            # Create and return audio file\n",
    "            audio_base64 = base64.b64encode(audio_content).decode('utf-8')\n",
    "            return {\"audio\": audio_base64}\n",
    "        else:  # If conversion failed\n",
    "            raise HTTPException(status_code=500, detail=\"TTS conversion failed\")\n",
    "\n",
    "    except Exception as e:  # If any error occured\n",
    "        raise HTTPException(status_code=500, detail=f\"TTS error: {e}\")\n",
    "\n",
    "@app_backend.post(\"/stt\")\n",
    "async def speech_to_text_endpoint(request: STTRequest):\n",
    "    \"\"\"\n",
    "    Convert speech to text\n",
    "    \"\"\"\n",
    "    try:\n",
    "        audio_bytes = base64.b64decode(request.audio_data)\n",
    "        # Pass the audio, sample rate and topic to the helper function\n",
    "        transcript = speech_to_text(audio_bytes, stt_client, request.sample_rate, request.topic)\n",
    "        return {\"transcript\": transcript}\n",
    "\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"STT error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNt-s1-64UPe"
   },
   "source": [
    "## 4. Frontend\n",
    "\n",
    "This section creates the user interface using Streamlit. The entire frontend code is written to a file named app.py.\n",
    "\n",
    "**Page Layout:** It configures the page title, icon, and layout. It also defines the CSS for styling the app's components.\n",
    "\n",
    "**User Interface:**\n",
    "* It creates input fields for the user to enter a topic, select a language level, and choose a content type.\n",
    "\n",
    "* The generated content is displayed in a tabbed interface, separating the exercises into reading, writing, listening and speaking.\n",
    "\n",
    "* It includes interactive elements like text areas for submitting answers, buttons to generate audio and a real-time audio recorder for the speaking exercises.\n",
    "\n",
    "**API Interaction:** The frontend sends requests to the FastAPI backend to generate content, get feedback and handle audio processing. It then displays the results returned by the backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "define_streamlit",
    "outputId": "dec90600-3e7e-4ce5-dd32-c29bc20f0bac"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Writing app.py\n"
     ]
    }
   ],
   "source": [
    "# Define the Streamlit frontend application\n",
    "\n",
    "# Create the python script that Streamlit will run\n",
    "%%writefile app.py\n",
    "\n",
    "# These imports are also at the start of the notebook. Without them here, the cell cannot be executed correctly, because app.py does not have access to other cells\n",
    "# Keep imports here!\n",
    "import streamlit as st\n",
    "import requests, json, base64, av, io, queue, re\n",
    "from streamlit_webrtc import webrtc_streamer, WebRtcMode\n",
    "import streamlit.components.v1 as components\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "\n",
    "class AudioRecorder:\n",
    "    \"\"\"This class will process and save the audio frames from the browser\"\"\"\n",
    "    def __init__(self):\n",
    "        self._frames = []\n",
    "\n",
    "    def recv(self, frame: av.AudioFrame) -> av.AudioFrame:\n",
    "        self._frames.append(frame)\n",
    "        return frame\n",
    "\n",
    "    def get_frames(self):\n",
    "        return self._frames\n",
    "\n",
    "    def clear_frames(self):\n",
    "        self._frames = []\n",
    "\n",
    "# Page configuration\n",
    "st.set_page_config(\n",
    "    page_title=\"KultuRAG\",\n",
    "    page_icon=\"ğŸŒ\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"auto\"\n",
    ")\n",
    "\n",
    "# API URL is fixed to the local backend\n",
    "API_URL = \"http://localhost:8000\"\n",
    "\n",
    "# CSS for styling\n",
    "st.markdown(\"\"\"\n",
    "<style>\n",
    "    .main-header {\n",
    "        text-align: center;\n",
    "        padding: 1rem 0;\n",
    "        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);\n",
    "        color: white;\n",
    "        border-radius: 10px;\n",
    "        margin-bottom: 2rem;\n",
    "    }\n",
    "    .info-box {\n",
    "        background-color: #f0f2f6;\n",
    "        padding: 1rem;\n",
    "        border-radius: 10px;\n",
    "        margin: 1rem 0;\n",
    "    }\n",
    "    .success-box {\n",
    "        background-color: #d4edda; color: #155724;\n",
    "        padding: 1.5rem; border-radius: 10px; border: 1px solid #c3e6cb;\n",
    "        margin: 1rem 0;\n",
    "    }\n",
    "    .error-box {\n",
    "        background-color: #f8d7da; color: #721c24;\n",
    "        padding: 1rem; border-radius: 10px; border: 1px solid #f5c6cb;\n",
    "        margin: 1rem 0;\n",
    "    }\n",
    "    .exercise-box {\n",
    "        background-color: #f8f9fa;\n",
    "        padding: 1.5rem;\n",
    "        border-radius: 10px;\n",
    "        border: 2px solid #dee2e6;\n",
    "        margin: 1.5rem 0;\n",
    "    }\n",
    "    .feedback-box {\n",
    "        background-color: #e7f3ff;\n",
    "        padding: 1rem;\n",
    "        border-radius: 10px;\n",
    "        border: 1px solid #b3d9ff;\n",
    "        margin: 1rem 0;\n",
    "    }\n",
    "</style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# Initialize session state\n",
    "if 'generated_content' not in st.session_state:\n",
    "    st.session_state.generated_content = None\n",
    "if 'exercises' not in st.session_state:\n",
    "    st.session_state.exercises = None\n",
    "if 'audio_data' not in st.session_state:\n",
    "    st.session_state.audio_data = None\n",
    "if 'recorded_audio' not in st.session_state:\n",
    "    st.session_state.recorded_audio = None\n",
    "\n",
    "# Header\n",
    "st.markdown(\"\"\"\n",
    "<div class=\"main-header\">\n",
    "    <h1>ğŸŒ KultuRAG - Cultural AI Language Learning Assistant</h1>\n",
    "    <p>Erlebe KI-generierte Inhalte basierend auf kulturellem Wissen</p>\n",
    "</div>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# Sidebar for health check\n",
    "st.sidebar.title(\"âš™ï¸ Systemstatus\")\n",
    "if st.sidebar.button(\"ğŸ” Backend-Status prÃ¼fen\"):  # If option is chosen\n",
    "    try:\n",
    "        response = requests.get(f\"{API_URL}/health\", timeout=5)  # Get response of the backend API endpoint\n",
    "        if response.status_code == 200:  # If working\n",
    "            st.sidebar.success(\"âœ… Backend verbunden!\")\n",
    "            st.sidebar.json(response.json())\n",
    "        else:  # If not working\n",
    "            st.sidebar.error(f\"âŒ Backend antwortet nicht (Status: {response.status_code})\")\n",
    "    except Exception as e:  # If something else failed\n",
    "        st.sidebar.error(f\"âŒ Verbindungsfehler: {e}\")\n",
    "st.sidebar.info(f\"Das Frontend ist fest mit dem lokalen Backend unter `{API_URL}` verbunden.\")\n",
    "\n",
    "\n",
    "# Main content\n",
    "col1, col2 = st.columns([2, 1])  # Columns\n",
    "\n",
    "# Column 1\n",
    "with col1:\n",
    "    st.markdown(\"### ğŸ“ Lerninhalt erstellen\")  # Title\n",
    "    thema = st.text_input(\"âœï¸ Thema eingeben\", placeholder=\"z.B. Deutsche KÃ¼che, Oktoberfest...\")  # Text box for topic with instructions and examples\n",
    "    sprachniveau = st.selectbox(\"ğŸ“š Sprachniveau wÃ¤hlen\", options=[\"A1\", \"A2\", \"B1\", \"B2\", \"C1\", \"C2\"], index=2)  # Select box with options for language level\n",
    "    inhaltstyp = st.radio(\"ğŸ­ Inhaltstyp wÃ¤hlen\", options=['Kurztext', 'Langtext', 'Geschichte', 'MÃ¤rchen', 'Dialog',\n",
    "                   'Interview', 'Redewendung', 'Rolenspiel', 'Gedicht', 'Drama', 'Liedtext',\n",
    "                   'Online-GesprÃ¤ch', 'Jugendsprache'], horizontal=True)  # Selecion of content generation type\n",
    "\n",
    "# Column 2\n",
    "with col2:\n",
    "    st.markdown(\"### ğŸ’¡ Tipps\")  # Title\n",
    "    # Description box\n",
    "    st.markdown(\"\"\"\n",
    "    <div class=\"info-box\" style=\"color: black;\">\n",
    "    <strong>ğŸ“‹ Interessante Themen:</strong><br>\n",
    "    â€¢ Deutsche Traditionen<br>\n",
    "    â€¢ StÃ¤dte und Regionen<br>\n",
    "    â€¢ Essen und Trinken<br>\n",
    "    â€¢ Kunst und Kultur<br>\n",
    "    </div>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# Generate Button to send inputs to the backend and generate response\n",
    "if st.button(\"ğŸš€ Inhalt und Ãœbungen generieren\", type=\"primary\", use_container_width=True):  # If user clicks on button\n",
    "    if not thema or len(thema.strip()) < 2:  # If there is no topic or topic is not valid\n",
    "        st.error(\"âŒ Bitte gib ein gÃ¼ltiges Thema ein (mindestens 2 Zeichen)\")\n",
    "    else:  # If topic exists and is valid\n",
    "        with st.spinner('Generiere personalisierten Lerninhalt und interaktive Ãœbungen...'):\n",
    "            try: # Content generation\n",
    "                # Get inputs\n",
    "                request_data = {\n",
    "                    \"thema\": thema.strip(),\n",
    "                    \"sprachniveau\": sprachniveau,\n",
    "                    \"inhaltstyp\": inhaltstyp\n",
    "                }\n",
    "\n",
    "                # Generate all content and exercises\n",
    "                response = requests.post(f\"{API_URL}/generate_exercises\", json=request_data, timeout=120)\n",
    "\n",
    "                if response.status_code == 200:  # If content was successfully generated\n",
    "                    data = response.json()\n",
    "                    st.session_state.generated_content = data\n",
    "                    st.session_state.exercises = {\n",
    "                        'thema': thema,\n",
    "                        'sprachniveau': sprachniveau,\n",
    "                        'inhaltstyp': inhaltstyp\n",
    "                    }\n",
    "                else:  # If content was not successfully generated\n",
    "                    error_detail = response.json().get(\"detail\", response.text)\n",
    "                    st.error(f\"Backend-Fehler: {error_detail}\")\n",
    "\n",
    "            except Exception as e:  # If something failed\n",
    "                st.error(f\"ğŸš¨ Fehler: {e}\")\n",
    "\n",
    "# Display generated content\n",
    "if st.session_state.generated_content:  # If content is available\n",
    "    data = st.session_state.generated_content\n",
    "\n",
    "    # Success info box\n",
    "    st.markdown(\"---\")\n",
    "    st.markdown(\"### Generierter Lerninhalt\")\n",
    "    st.markdown(f\"\"\"\n",
    "    <div class=\"success-box\">\n",
    "        <strong>ğŸ“Š Details:</strong><br>\n",
    "        ğŸ¯ Thema: {st.session_state.exercises['thema']}<br>\n",
    "        ğŸ“š Niveau: {st.session_state.exercises['sprachniveau']}<br>\n",
    "        ğŸ“ Typ: {st.session_state.exercises['inhaltstyp']}\n",
    "    </div>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "    # Create tabs for the different content sections\n",
    "    tab1, tab2, tab3, tab4 = st.tabs([\"ğŸ“– Leseverstehen\", \"âœï¸ SchreibÃ¼bung\",\n",
    "                                             \"ğŸ§ HÃ¶rÃ¼bung\", \"ğŸ¤ SprechÃ¼bung\"])\n",
    "\n",
    "    # Tab 1: Main Content - Leseverstehen\n",
    "    with tab1:\n",
    "        st.markdown(data.get(\"main_content\", \"\"))\n",
    "\n",
    "        # Add feedback button for submitting existing exercise\n",
    "        st.markdown(\"### ğŸ“ Ãœbung einreichen\")\n",
    "        # Get exercise from user\n",
    "        original_exercise_answer = st.text_area(\"Deine Antwort zur Ãœbung:\",\n",
    "                                               key=\"original_exercise\",\n",
    "                                               height=150)\n",
    "        # Show disclaimer about the possibility to redo the exercise after submitting it\n",
    "        st.markdown(\"<small style='color: #666;'>ğŸ’¡ Hinweis: Du kannst die Ãœbung nach dem Absenden jederzeit erneut bearbeiten.</small>\",\n",
    "        unsafe_allow_html=True)\n",
    "\n",
    "        if st.button(\"Ãœbung korrigieren\", key=\"correct_original\"):  # If user clicks on button\n",
    "            if original_exercise_answer:  # If user did the exercise\n",
    "                with st.spinner(\"Korrigiere Ãœbung...\"):\n",
    "                    # Get data\n",
    "                    try:\n",
    "                        feedback_request = {\n",
    "                            \"exercise_type\": \"Ãœbung\",\n",
    "                            \"level\": st.session_state.exercises['sprachniveau'],\n",
    "                            \"topic\": st.session_state.exercises['thema'],\n",
    "                            \"task_instructions\": \"Siehe Ãœbung im Hauptinhalt\",\n",
    "                            \"user_response\": original_exercise_answer\n",
    "                        }\n",
    "\n",
    "                        # Generate feedback\n",
    "                        feedback_response = requests.post(f\"{API_URL}/feedback\",\n",
    "                                                         json=feedback_request,\n",
    "                                                         timeout=30)\n",
    "\n",
    "                        if feedback_response.status_code == 200:  # If feedback was generated\n",
    "                            feedback_data = feedback_response.json()\n",
    "                            # Show feedback\n",
    "                            st.markdown(f\"\"\"\n",
    "                            <div class=\"feedback-box\" style=\"color: black;\">\n",
    "                            {feedback_data['feedback']}\n",
    "                            </div>\n",
    "                            \"\"\", unsafe_allow_html=True)\n",
    "                    except Exception as e:  # If something failed\n",
    "                        st.error(f\"Fehler beim Feedback: {e}\")\n",
    "            else:  # If user did not do the exercise\n",
    "                st.warning(\"Bitte gib erst eine Antwort ein.\")\n",
    "\n",
    "    # Tab 2: Writing Exercise\n",
    "    with tab2:\n",
    "        st.markdown(data.get(\"writing_exercise\", \"\"))\n",
    "\n",
    "        # Text input for writing exercise\n",
    "        st.markdown(\"### âœï¸ Dein Text\")\n",
    "        writing_input = st.text_area(\"Schreibe hier deinen Text:\",\n",
    "                                    key=\"writing_input\",\n",
    "                                    height=200)\n",
    "        # Show disclaimer about the possibility to redo the exercise after submitting it\n",
    "        st.markdown(\"<small style='color: #666;'>ğŸ’¡ Hinweis: Du kannst die Ãœbung nach dem Absenden jederzeit erneut bearbeiten.</small>\",\n",
    "        unsafe_allow_html=True)\n",
    "\n",
    "        if st.button(\"Text einreichen\", key=\"submit_writing\"):  # If user clicks on button\n",
    "            if writing_input:  # If user did the exercise\n",
    "                with st.spinner(\"Analysiere deinen Text...\"):\n",
    "                    # Get data\n",
    "                    try:\n",
    "                        feedback_request = {\n",
    "                            \"exercise_type\": \"SchreibÃ¼bung\",\n",
    "                            \"level\": st.session_state.exercises['sprachniveau'],\n",
    "                            \"topic\": st.session_state.exercises['thema'],\n",
    "                            \"task_instructions\": data.get(\"writing_exercise\", \"\"),\n",
    "                            \"user_response\": writing_input\n",
    "                        }\n",
    "\n",
    "                        # Generate response\n",
    "                        feedback_response = requests.post(f\"{API_URL}/feedback\",\n",
    "                                                         json=feedback_request,\n",
    "                                                         timeout=30)\n",
    "\n",
    "                        if feedback_response.status_code == 200:  # If feedback was generated\n",
    "                            feedback_data = feedback_response.json()\n",
    "                            # Show feedback\n",
    "                            st.markdown(f\"\"\"\n",
    "                            <div class=\"feedback-box\" style=\"color: black;\">\n",
    "                            {feedback_data['feedback']}\n",
    "                            </div>\n",
    "                            \"\"\", unsafe_allow_html=True)\n",
    "                    except Exception as e:  # If something failed\n",
    "                        st.error(f\"Fehler beim Feedback: {e}\")\n",
    "            else:  # If user did not do the exercise\n",
    "                st.warning(\"Bitte schreibe erst einen Text.\")\n",
    "\n",
    "    # Tab 3: Audio Comprehension\n",
    "    with tab3:\n",
    "        audio_content = data.get(\"audio_exercise\", \"\") # Get audio content\n",
    "        audio_text = \"\"\n",
    "        comprehension_questions = \"\"\n",
    "\n",
    "        # Split content into audio script and questions\n",
    "        # Define all possible separators\n",
    "        separators = [\n",
    "            \"**ğŸ“‹ VERSTÃ„NDNISFRAGEN**\",\n",
    "            \"*ğŸ“‹ VERSTÃ„NDNISFRAGEN*\",\n",
    "            \"ğŸ“‹ VERSTÃ„NDNISFRAGEN\",\n",
    "            \"**VERSTÃ„NDNISFRAGEN**\",\n",
    "            \"*VERSTÃ„NDNISFRAGEN*\",\n",
    "            \"VERSTÃ„NDNISFRAGEN\",\n",
    "            \"VerstÃ¤ndnisfragen\"\n",
    "        ]\n",
    "\n",
    "        found_separator = None  # Save here the found separator\n",
    "        for sep in separators:\n",
    "            if sep in audio_content:\n",
    "                found_separator = sep\n",
    "                break  # Stop searching once a separator is found\n",
    "\n",
    "        if found_separator:  # If a separator was found\n",
    "            # Split the content\n",
    "            parts = audio_content.split(found_separator, 1)\n",
    "            audio_text = parts[0].strip()\n",
    "            comprehension_questions = found_separator + parts[1].strip()\n",
    "        else:  # If no separator is found after checking all possibilities\n",
    "            audio_text = audio_content\n",
    "            comprehension_questions = \"\"  # Ensure questions are empty if not found\n",
    "            st.warning(\"Ich konnte die VerstÃ¤ndnisfragen nicht vom HÃ¶rtext trennen\")\n",
    "\n",
    "        # Generate audio button\n",
    "        if audio_text:\n",
    "            if st.button(\"ğŸ”Š Audio fÃ¼r den HÃ¶rtext generieren\", key=\"generate_audio\"):\n",
    "                with st.spinner(\"Generiere Audio...\"):\n",
    "                    try:\n",
    "                        # Clean the text of markdown symbols (*, #, etc.) before sending\n",
    "                        cleaned_text = re.sub(r'[*#]', '', audio_text)\n",
    "\n",
    "                        # Generate speech using the cleaned text\n",
    "                        tts_request = {\"text\": cleaned_text}  # Sends clean text\n",
    "                        tts_response = requests.post(f\"{API_URL}/tts\", json=tts_request, timeout=60)\n",
    "\n",
    "                        if tts_response.status_code == 200:  # If speech was successfully generated\n",
    "                            audio_data = tts_response.json()[\"audio\"]\n",
    "                            st.session_state.audio_data = audio_data\n",
    "                            st.success(\"Audio erfolgreich generiert!\")\n",
    "                        else:\n",
    "                            st.error(f\"Fehler bei Audio-Generierung: {tts_response.text}\")\n",
    "                    except Exception as e:  # If speech was not successfully generated\n",
    "                        st.error(f\"Fehler bei Audio-Generierung: {e}\")\n",
    "\n",
    "        # Play audio if available\n",
    "        if st.session_state.get('audio_data'):  # If audio exists\n",
    "            audio_bytes = base64.b64decode(st.session_state.audio_data)\n",
    "            st.audio(audio_bytes, format='audio/mp3')\n",
    "            if st.button(\"Audio-Player entfernen\", key=\"clear_audio\"):\n",
    "                st.session_state.audio_data = None\n",
    "                st.rerun()\n",
    "\n",
    "        st.markdown(\"---\")\n",
    "        # Display questions permanently\n",
    "        if comprehension_questions:\n",
    "            st.markdown(comprehension_questions)\n",
    "\n",
    "        # Show transcription in an expander\n",
    "        with st.expander(\"ğŸ“– Transkription des HÃ¶rtextes anzeigen\"):\n",
    "            st.markdown(audio_text if audio_text else \"Kein Transkript verfÃ¼gbar.\")\n",
    "\n",
    "        # Answer input for comprehension questions\n",
    "        st.markdown(\"### ğŸ“‹ Deine Antworten\")\n",
    "        audio_answers = st.text_area(\"Beantworte die VerstÃ¤ndnisfragen:\", key=\"audio_answers\", height=150)\n",
    "        # Show disclaimer about the possibility to redo the exercise after submitting it\n",
    "        st.markdown(\"<small style='color: #666;'>ğŸ’¡ Hinweis: Du kannst die Ãœbung nach dem Absenden jederzeit erneut bearbeiten.</small>\", unsafe_allow_html=True)\n",
    "\n",
    "        if st.button(\"Antworten einreichen\", key=\"submit_audio\"):  # If user clicks on button\n",
    "            if audio_answers:  # If user did the exercise\n",
    "                with st.spinner(\"Korrigiere Antworten...\"):\n",
    "                    try:\n",
    "                        # Get inputs\n",
    "                        feedback_request = {\n",
    "                            \"exercise_type\": \"HÃ¶rverstÃ¤ndnis\",\n",
    "                            \"level\": st.session_state.exercises['sprachniveau'],\n",
    "                            \"topic\": st.session_state.exercises['thema'],\n",
    "                            \"task_instructions\": comprehension_questions,  # Now correctly sends only the questions\n",
    "                            \"user_response\": audio_answers\n",
    "                        }\n",
    "\n",
    "                        # Generate feedback\n",
    "                        feedback_response = requests.post(f\"{API_URL}/feedback\", json=feedback_request, timeout=30)\n",
    "\n",
    "                        if feedback_response.status_code == 200:  # If feedback was successfully generated\n",
    "                            feedback_data = feedback_response.json()\n",
    "                            # Show feedback\n",
    "                            st.markdown(f\"<div class=\\\"feedback-box\\\" style=\\\"color: black;\\\">{feedback_data['feedback']}</div>\", unsafe_allow_html=True)\n",
    "                        else:\n",
    "                            st.error(f\"Feedback-Fehler: {feedback_response.text}\")\n",
    "                    except Exception as e:  # If something failed\n",
    "                        st.error(f\"Fehler beim Feedback: {e}\")\n",
    "            else:  # If user did not do the exercise\n",
    "                st.warning(\"Bitte beantworte erst die Fragen.\")\n",
    "\n",
    "    # Tab 4: Speaking Exercise\n",
    "    with tab4:\n",
    "        st.markdown(data.get(\"speaking_exercise\", \"\"))\n",
    "\n",
    "        # Audio recording section\n",
    "        st.markdown(\"### ğŸ¤ Sprachaufnahme\")\n",
    "\n",
    "        # Initiate recorder if it is not already initiated\n",
    "        if \"audio_recorder\" not in st.session_state:\n",
    "            st.session_state.audio_recorder = AudioRecorder()\n",
    "\n",
    "        # Create interface showing speaking process\n",
    "        webrtc_ctx = webrtc_streamer(\n",
    "            key=\"speaking-exercise\",\n",
    "            mode=WebRtcMode.SENDONLY,\n",
    "            audio_frame_callback=st.session_state.audio_recorder.recv,\n",
    "            media_stream_constraints={\"video\": False, \"audio\": True},\n",
    "        )\n",
    "\n",
    "        # Start interface\n",
    "        if webrtc_ctx.state.playing:\n",
    "            st.info(\"ğŸ¤ Aufnahme lÃ¤uft... Klicke auf 'Stop', um zu beenden.\")\n",
    "\n",
    "        if not webrtc_ctx.state.playing:\n",
    "          audio_frames = st.session_state.audio_recorder.get_frames()\n",
    "          if audio_frames and \"recorded_audio_info\" not in st.session_state:\n",
    "              with st.spinner(\"Verarbeite Aufnahme...\"):\n",
    "                  # Get the sample rate and channel info from the first frame.\n",
    "                  sample_rate = audio_frames[0].sample_rate\n",
    "                  sample_width = audio_frames[0].format.bits // 8\n",
    "\n",
    "                  # Create an empty AudioSegment to build the full audio.\n",
    "                  sound = AudioSegment.empty()\n",
    "\n",
    "                  # Append each audio frame to the master AudioSegment.\n",
    "                  # pydub handles the conversion from raw bytes correctly.\n",
    "                  for frame in audio_frames:\n",
    "                      sound += AudioSegment(\n",
    "                          data=frame.to_ndarray().tobytes(),\n",
    "                          sample_width=sample_width,\n",
    "                          frame_rate=sample_rate,\n",
    "                          channels=len(frame.layout.channels)\n",
    "                      )\n",
    "\n",
    "                  # Export the final combined audio to a WAV format in memory.\n",
    "                  buffer = io.BytesIO()\n",
    "                  # Convert to mono and then export\n",
    "                  sound.set_channels(1).export(buffer, format=\"wav\")\n",
    "\n",
    "                  # Store the correct WAV bytes and sample rate in the session state.\n",
    "                  st.session_state.recorded_audio_info = {\"bytes\": buffer.getvalue(), \"rate\": sample_rate}\n",
    "                  st.session_state.audio_recorder.clear_frames()\n",
    "                  st.rerun()\n",
    "\n",
    "        if \"recorded_audio_info\" in st.session_state:  # If audio was recorded\n",
    "            st.success(\"âœ”ï¸ Aufnahme abgeschlossen.\")\n",
    "            # Play back the audio from the stored bytes\n",
    "            st.audio(st.session_state.recorded_audio_info[\"bytes\"], format=\"audio/wav\")\n",
    "\n",
    "            # Show two options: submit audio and delete\n",
    "            col_submit, col_delete = st.columns(2)\n",
    "            with col_submit:  # Submit option\n",
    "                if st.button(\"âœ”ï¸ Aufnahme zur Auswertung senden\", use_container_width=True):  # If user clicks on submit\n",
    "                    with st.spinner(\"Transkribere und bewerte deine Aufnahme...\"):\n",
    "                        try:\n",
    "                            # Get both bytes and rate from session state\n",
    "                            recorded_info = st.session_state.recorded_audio_info\n",
    "                            b64_audio = base64.b64encode(recorded_info[\"bytes\"]).decode()\n",
    "\n",
    "                            # Send the audio and the correct sample rate to the backend\n",
    "                            stt_request = {\n",
    "                                \"audio_data\": b64_audio,\n",
    "                                \"sample_rate\": recorded_info[\"rate\"],\n",
    "                                \"topic\": st.session_state.exercises['thema']\n",
    "                            }\n",
    "                            stt_response = requests.post(f\"{API_URL}/stt\", json=stt_request, timeout=60)\n",
    "\n",
    "                            if stt_response.status_code == 200:\n",
    "                                transcript = stt_response.json()[\"transcript\"]\n",
    "                                if not transcript:\n",
    "                                    st.warning(\"Konnte nichts aus der Aufnahme transkribieren. Bitte sprich lauter und versuche es erneut.\")\n",
    "                                else:\n",
    "                                    st.info(f\"**Transkript deiner Aufnahme:**\\n\\n> {transcript}\")\n",
    "                                    feedback_request = {\n",
    "                                        \"exercise_type\": \"SprechÃ¼bung\",\n",
    "                                        \"level\": st.session_state.exercises['sprachniveau'],\n",
    "                                        \"topic\": st.session_state.exercises['thema'],\n",
    "                                        \"task_instructions\": data.get(\"speaking_exercise\", \"\"),\n",
    "                                        \"user_response\": transcript\n",
    "                                    }\n",
    "                                    feedback_response = requests.post(f\"{API_URL}/feedback\", json=feedback_request, timeout=30)\n",
    "                                    if feedback_response.status_code == 200:\n",
    "                                        feedback_data = feedback_response.json()\n",
    "                                        st.markdown(f\"<div class=\\\"feedback-box\\\" style=\\\"color: black;\\\">{feedback_data['feedback']}</div>\", unsafe_allow_html=True)\n",
    "                                    else:\n",
    "                                        st.error(f\"Feedback-Fehler: {feedback_response.text}\")\n",
    "                            else:\n",
    "                                st.error(f\"Fehler bei der Transkription: {stt_response.text}\")\n",
    "                        except Exception as e:\n",
    "                            st.error(f\"Ein Fehler ist aufgetreten: {e}\")\n",
    "\n",
    "            with col_delete:  # Button to delete recorded audio\n",
    "                if st.button(\"ğŸ—‘ï¸ Aufnahme lÃ¶schen\", use_container_width=True):  # If user clicks on it\n",
    "                    # Clear the processed audio info if it exists\n",
    "                    if \"recorded_audio_info\" in st.session_state:\n",
    "                        del st.session_state.recorded_audio_info\n",
    "\n",
    "                    # Also clear any raw frames from the recorder object\n",
    "                    st.session_state.audio_recorder.clear_frames()\n",
    "\n",
    "                    st.rerun()\n",
    "\n",
    "        st.markdown(\"---\")\n",
    "        # Alternative: Manual text input for speaking exercise\n",
    "        st.markdown(\"### ğŸ“ Alternative: Text eingeben\")\n",
    "        speaking_text = st.text_area(\"Gib hier ein, was du sagen wÃ¼rdest (falls die Aufnahme nicht funktioniert):\",\n",
    "                                    key=\"speaking_text\", height=150)\n",
    "\n",
    "        if st.button(\"Text zur Auswertung senden\", key=\"submit_speaking_text\"):  # Button to send text to be corrected\n",
    "            if speaking_text:  # If user introduced a text\n",
    "                with st.spinner(\"Analysiere deine Antwort...\"):\n",
    "                    try:\n",
    "                        feedback_request = {\n",
    "                            \"exercise_type\": \"SprechÃ¼bung (als Text)\",\n",
    "                            \"level\": st.session_state.exercises['sprachniveau'],\n",
    "                            \"topic\": st.session_state.exercises['thema'],\n",
    "                            \"task_instructions\": data.get(\"speaking_exercise\", \"\"),\n",
    "                            \"user_response\": speaking_text\n",
    "                        }\n",
    "                        feedback_response = requests.post(f\"{API_URL}/feedback\", json=feedback_request, timeout=30)  # Generate feedback\n",
    "                        if feedback_response.status_code == 200:  # If feedback was generated\n",
    "                            feedback_data = feedback_response.json()\n",
    "                            st.markdown(f\"<div class=\\\"feedback-box\\\" style=\\\"color: black;\\\">{feedback_data['feedback']}</div>\", unsafe_allow_html=True)\n",
    "                        else:  # If feedback was not generated\n",
    "                             st.error(f\"Feedback-Fehler: {feedback_response.text}\")\n",
    "                    except Exception as e:  # If there was an error\n",
    "                        st.error(f\"Fehler beim Feedback: {e}\")\n",
    "            else:  # If user introduced no text\n",
    "                st.warning(\"Bitte gib erst einen Text ein.\")\n",
    "\n",
    "# Footer\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"\"\"\n",
    "<div style=\"text-align: center; color: #666; padding: 1rem;\">\n",
    "    ğŸ¤– Powered by KultuRAG AI â€¢ Made with â¤ï¸ by Alberto SÃ¡nchez\n",
    "    <br><br>\n",
    "    <small style=\"color: white;\">âš ï¸ This app provides AI-generated learning content. While we strive for accuracy and educational value, the material may contain errors or limitations.\n",
    "    The app is not a substitute for qualified language instruction. Please use with critical judgment âš ï¸</small>\n",
    "</div>\n",
    "\"\"\", unsafe_allow_html=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXePEOiI4ibA"
   },
   "source": [
    "## 5. Servers\n",
    "\n",
    "This final section launches the application.\n",
    "\n",
    "**Server Threads:** It starts the FastAPI backend and the Streamlit frontend on separate threads, allowing them to run simultaneously.\n",
    "\n",
    "**Ngrok Tunnel:** It uses ngrok to create a public URL that forwards to the Streamlit frontend. This makes the application running inside the Google Colab notebook accessible on the internet.\n",
    "\n",
    "**Keep-Alive:** A final cell runs an infinite loop to keep the Colab session active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "start_servers",
    "outputId": "1a07d1e6-9492-4882-bde9-c8a7d1cfe6bc"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting FastAPI backend on port 8000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:     Started server process [799]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting Streamlit frontend on port 8501\n",
      "KultuRAG app is live\n",
      "Public URL: NgrokTunnel: \"https://hugely-giving-pelican.ngrok-free.app/" -> \"http://localhost:8501\"\n"
     ]
    }
   ],
   "source": [
    "# Start servers and launch ngrok tunnel\n",
    "\n",
    "# Kill any previous ngrok tunnel\n",
    "ngrok.kill()\n",
    "\n",
    "# Set ngrok auth token\n",
    "ngrok.set_auth_token(ngrok_auth_token)\n",
    "\n",
    "# Function to run FastAPI backend\n",
    "def run_fastapi():\n",
    "    uvicorn.run(app_backend, host=\"0.0.0.0\", port=8000)\n",
    "\n",
    "# Function to run Streamlit frontend\n",
    "def run_streamlit():\n",
    "    os.system(\"streamlit run app.py --server.port 8501 --server.headless true\")\n",
    "\n",
    "# Start both servers in background threads\n",
    "fastapi_thread = threading.Thread(target=run_fastapi, daemon=True)  # Backend\n",
    "streamlit_thread = threading.Thread(target=run_streamlit, daemon=True)  # Frontend\n",
    "\n",
    "print(\"Starting FastAPI backend on port 8000\")\n",
    "fastapi_thread.start()\n",
    "time.sleep(5)  # Give backend time to start\n",
    "\n",
    "print(\"Starting Streamlit frontend on port 8501\")\n",
    "streamlit_thread.start()\n",
    "time.sleep(5)  # Give frontend time to start\n",
    "\n",
    "# Create a public ngrok tunnel to the Streamlit port\n",
    "public_url = ngrok.connect(8501, domain='https://hugely-giving-pelican.ngrok-free.app/')  # Static domain automatically asigned by ngrok\n",
    "print(\"KultuRAG app is live\")\n",
    "print(f\"Public URL: {public_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "keep_alive",
    "outputId": "e92a7da6-ee02-43e2-9102-16f3c136ec32"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "App is running. This cell will keep the Colab session alive.\n",
      "Still alive\n",
      "Received request: Liebe | B2 | Geschichte\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /usr/local/lib/python3.12/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:     127.0.0.1:56138 - \"POST /generate_exercises HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:57066 - \"POST /tts HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "# Keep the notebook running to avoid that the server stops quickly\n",
    "\n",
    "print(\"App is running. This cell will keep the Colab session alive\")\n",
    "try:\n",
    "    while True:\n",
    "        time.sleep(3600)  # Keep alive for an hour at a time\n",
    "        print(\"Still alive\")\n",
    "except KeyboardInterrupt:  # If execution is interrupted by the user\n",
    "    print(\"\\nShutting down servers and ngrok tunnel\")\n",
    "    ngrok.kill()  # Stop execution\n",
    "    print(\"Shutdown complete\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
